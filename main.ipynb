{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "I1T6NCelA33d"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script can be used as skelton code to read the challenge train and test\n",
    "geojsons, to train a trivial model, and write data to the submission file.\n",
    "\"\"\"\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "from shapely.geometry import Polygon, Point\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random as rd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-rmd_9sz1h0n"
   },
   "outputs": [],
   "source": [
    "df = gpd.read_file('train.geojson', index_col=0)\n",
    "df = df.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WJj1g2PoB1f0"
   },
   "outputs": [],
   "source": [
    "df_submission = gpd.read_file('test.geojson', index_col=0)\n",
    "df_submission = df_submission.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHEyPjfO9taj"
   },
   "source": [
    "# **2) Preprocessing data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KaK_Ewh3qAuB"
   },
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "m = len(df_submission)\n",
    "\n",
    "# Change_status_date encoder\n",
    "status_date = pd.concat([df['change_status_date1'], df['change_status_date2'], df['change_status_date3'], df['change_status_date4'], df['change_status_date5']])\n",
    "encoder_status_date = LabelEncoder()\n",
    "encoder_status_date.fit(status_date)\n",
    "\n",
    "# List of urban_types\n",
    "urban_types = []\n",
    "for i in range(n):\n",
    "  new = df['urban_types'][i].split(',')\n",
    "  for word in new:\n",
    "    if not (word in urban_types):\n",
    "      urban_types.append(word)\n",
    "\n",
    "# List of geography_types\n",
    "geography_types = []\n",
    "for i in range(n):\n",
    "  new = df['geography_types'][i].split(',')\n",
    "  for word in new:\n",
    "    if not (word in geography_types):\n",
    "      geography_types.append(word)\n",
    "\n",
    "for i in range(m):\n",
    "  new = df_submission['geography_types'][i].split(',')\n",
    "  for word in new:\n",
    "    if not (word in geography_types):\n",
    "      geography_types.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycNOmf2jkTmb"
   },
   "source": [
    "### Encoding functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "n7XZu1dUkzlJ"
   },
   "outputs": [],
   "source": [
    "# Encoding of change_status_date\n",
    "def encode_change_status_date(df):\n",
    "  for i in '12345':\n",
    "    df['change_status_date'+i] = encoder_status_date.transform(df['change_status_date'+i])\n",
    "  \n",
    "  return df\n",
    "\n",
    "# Adding the number of times each category 'change_status_date' is present in a row\n",
    "def add_number_change(df):\n",
    "    n = len(df)\n",
    "    l = [0 for i in range(n)]\n",
    "    for i in range(10):\n",
    "        df['number_of_change'+str(i)] = l.copy()\n",
    "    \n",
    "    for i in range(1,6):\n",
    "        for j in range(n):\n",
    "            label = str(df['change_status_date'+str(i)][j])\n",
    "            df['number_of_change'+str(label)][j] += 1\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Encoding of dates\n",
    "def encode_dates(df):\n",
    "  def distance_dates(date1, date2):\n",
    "    return abs((date(int(date2[2]), int(date2[1]), int(date2[0])) - date(int(date1[2]), int(date1[1]), int(date1[0]))).days)\n",
    "\n",
    "  n = len(df)\n",
    "  for i in range(n):\n",
    "    date1, date2, date3, date4, date5 = df['date1'][i].split('-'),  df['date2'][i].split('-'),  df['date3'][i].split('-'), df['date4'][i].split('-'), df['date5'][i].split('-')\n",
    "    \n",
    "    df['date5'][i] = distance_dates(date4, date5)\n",
    "    df['date4'][i] = distance_dates(date3, date4)\n",
    "    df['date3'][i] = distance_dates(date2, date3)\n",
    "    df['date2'][i] = distance_dates(date1, date2)\n",
    "    df['date1'][i] = 0\n",
    "\n",
    "  return df\n",
    "\n",
    "# Encoding of urban_types\n",
    "def encode_urban_types(df):\n",
    "  n = len(df)\n",
    "  for urban in urban_types:\n",
    "    df[urban] = np.zeros(n, dtype=int)\n",
    "\n",
    "  for i in range(n):\n",
    "    urbans = df['urban_types'][i].split(',')\n",
    "    for urban in urbans:\n",
    "      df[urban][i] = 1 \n",
    "\n",
    "  df = df.drop(columns=['urban_types'])\n",
    "\n",
    "  return df\n",
    "\n",
    "# Encoding of geography_types\n",
    "def encode_geography_types(df):\n",
    "  n = len(df)\n",
    "  for geography in geography_types:\n",
    "    df[geography] = np.zeros(n, dtype=int)\n",
    "\n",
    "  for i in range(n):\n",
    "    geographies = df['geography_types'][i].split(',')\n",
    "    for geography in geographies:\n",
    "      df[geography][i] = 1 \n",
    "\n",
    "  df = df.drop(columns=['geography_types'])\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polygon encoding functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding of polygon\n",
    "def get_aspect_ratio(poly):\n",
    "  bounds = poly.bounds\n",
    "  dist_y = bounds[2] - bounds[0]\n",
    "  dist_x = bounds[3] - bounds[1]\n",
    "  return min(dist_x/dist_y, dist_y/dist_x)\n",
    "\n",
    "def get_dist_x(poly):\n",
    "  bounds = poly.bounds\n",
    "  return (bounds[3] - bounds[1])\n",
    "\n",
    "def get_dist_y(poly):\n",
    "  bounds = poly.bounds\n",
    "  return (bounds[2] - bounds[0])\n",
    "\n",
    "def encode_polygon(df):\n",
    "  df['area'] = np.asarray(df[['geometry']].area)\n",
    "  df['length'] = np.asarray(df[['geometry']].length)\n",
    "  df['min_x'] = df['geometry'].apply(lambda poly: poly.bounds[0])\n",
    "  df['max_x'] = df['geometry'].apply(lambda poly: poly.bounds[2])\n",
    "  df['min_y'] = df['geometry'].apply(lambda poly: poly.bounds[1])\n",
    "  df['max_y'] = df['geometry'].apply(lambda poly: poly.bounds[3])\n",
    "  df['dist_x'] = (df['max_x'] - df['min_x'])*10000\n",
    "  df['dist_y'] = (df['max_y'] - df['min_y'])*10000\n",
    "  df['number_of_points'] = df['geometry'].apply(lambda poly: len(poly.exterior.coords))\n",
    "  df['aspect_ratio'] = df['geometry'].apply(get_aspect_ratio)\n",
    "  df['area_around'] = df['dist_x']*df['dist_y']\n",
    "\n",
    "  df = df.drop(columns=['geometry'])\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F0hEmrP1qaep",
    "outputId": "99e83091-0678-42ee-a0a8-a2bc7dddfc1e"
   },
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "import time as t\n",
    "\n",
    "def preprocess_data(df):\n",
    "  t1 = t.time()\n",
    "  df = encode_change_status_date(df)\n",
    "  print(\"Step 1/6 completed - Time : \", t.time()-t1)\n",
    "\n",
    "  t1 = t.time()\n",
    "  df = add_number_change(df)\n",
    "  print(\"Step 2/6 completed - Time : \", t.time()-t1)\n",
    "    \n",
    "  t1 = t.time()\n",
    "  df = encode_dates(df)\n",
    "  df = df.drop(columns=['date1'])\n",
    "  print(\"Step 3/6 completed - Time : \", t.time()-t1)\n",
    "\n",
    "  t1 = t.time()\n",
    "  df = encode_urban_types(df)\n",
    "  df = df.rename(columns={'None': 'None_urban'}, inplace=False)\n",
    "  print(\"Step 4/6 completed - Time : \", t.time()-t1)\n",
    "\n",
    "  t1 = t.time()\n",
    "  df = encode_geography_types(df)\n",
    "  df = df.rename(columns={'None': 'None_geography'}, inplace=False)\n",
    "  print(\"Step 5/6 completed - Time : \", t.time()-t1)\n",
    "\n",
    "  t1 = t.time()\n",
    "  df = encode_polygon(df)\n",
    "  print(\"Step 6/6 completed - Time : \", t.time()-t1)\n",
    "\n",
    "  return df\n",
    "\n",
    "df = preprocess_data(df)\n",
    "df_submission = preprocess_data(df_submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding labels for the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(df):\n",
    "    change_type_map = {'Demolition': 0, 'Road': 1, 'Residential': 2, 'Commercial': 3, 'Industrial': 4,\n",
    "           'Mega Projects': 5}\n",
    "\n",
    "    df['change_type'] = df['change_type'].apply(lambda x: change_type_map[x])\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = encode_labels(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change_type</th>\n",
       "      <th>change_status_date1</th>\n",
       "      <th>change_status_date2</th>\n",
       "      <th>change_status_date3</th>\n",
       "      <th>change_status_date4</th>\n",
       "      <th>change_status_date5</th>\n",
       "      <th>date2</th>\n",
       "      <th>date3</th>\n",
       "      <th>date4</th>\n",
       "      <th>date5</th>\n",
       "      <th>...</th>\n",
       "      <th>Grass Land</th>\n",
       "      <th>Farms</th>\n",
       "      <th>Lakes</th>\n",
       "      <th>Barren Land</th>\n",
       "      <th>Coastal</th>\n",
       "      <th>Dense Forest</th>\n",
       "      <th>None_geography</th>\n",
       "      <th>Hills</th>\n",
       "      <th>Desert</th>\n",
       "      <th>Snow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>472</td>\n",
       "      <td>531</td>\n",
       "      <td>592</td>\n",
       "      <td>587</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>472</td>\n",
       "      <td>531</td>\n",
       "      <td>592</td>\n",
       "      <td>587</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>472</td>\n",
       "      <td>531</td>\n",
       "      <td>592</td>\n",
       "      <td>587</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>472</td>\n",
       "      <td>531</td>\n",
       "      <td>592</td>\n",
       "      <td>587</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>472</td>\n",
       "      <td>531</td>\n",
       "      <td>592</td>\n",
       "      <td>587</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   change_type  change_status_date1  change_status_date2  change_status_date3  \\\n",
       "0            3                    5                    1                    0   \n",
       "1            3                    4                    4                    0   \n",
       "2            3                    5                    5                    0   \n",
       "3            3                    5                    5                    1   \n",
       "4            3                    5                    5                    2   \n",
       "\n",
       "   change_status_date4  change_status_date5 date2 date3 date4 date5  ...  \\\n",
       "0                    0                    0   472   531   592   587  ...   \n",
       "1                    0                    0   472   531   592   587  ...   \n",
       "2                    0                    0   472   531   592   587  ...   \n",
       "3                    1                    0   472   531   592   587  ...   \n",
       "4                    1                    0   472   531   592   587  ...   \n",
       "\n",
       "   Grass Land  Farms  Lakes  Barren Land  Coastal  Dense Forest  \\\n",
       "0           1      0      0            0        0             0   \n",
       "1           1      0      0            0        0             0   \n",
       "2           1      0      0            0        0             0   \n",
       "3           1      0      0            0        0             0   \n",
       "4           1      0      0            0        0             0   \n",
       "\n",
       "   None_geography  Hills  Desert  Snow  \n",
       "0               0      0       0     0  \n",
       "1               0      0       0     0  \n",
       "2               0      0       0     0  \n",
       "3               0      0       0     0  \n",
       "4               0      0       0     0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing data (no longer useful since we use random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "W60c4A322pGq"
   },
   "outputs": [],
   "source": [
    "# max_perimeter = max(df['perimeter'])\n",
    "# max_aspect_ratio = max(df['aspect_ratio'])\n",
    "# max_area = max(df['area'])\n",
    "# max_date = max(pd.concat([df['date2'], df['date3'], df['date4'], df['date5']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "F66GU6gG21Ww"
   },
   "outputs": [],
   "source": [
    "# Data normalization\n",
    "def normalize_data(df):\n",
    "  n = len(df)\n",
    "  # df['perimeter'] /= max_perimeter\n",
    "  df['aspect_ratio'] /= max_aspect_ratio\n",
    "  df['area'] /= max_area\n",
    "  df['date2'] /= max_date\n",
    "  df['date3'] /= max_date\n",
    "  df['date4'] /= max_date\n",
    "  df['date5'] /= max_date\n",
    "\n",
    "  return df\n",
    "\n",
    "# df = normalize_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data augmentation (no longer useful)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at label repartition\n",
    "def count_labels(df):\n",
    "    a = df.groupby('change_type').count()\n",
    "    n = len(a)\n",
    "    print(\"Le nombre de labels par catégorie est : \")\n",
    "    for i in range(n):\n",
    "        print(\"Catégorie \" + str(i) + \" : \", a['date2'][i])\n",
    "        \n",
    "count_labels(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(df, labels=[], ratio_geog=10, ratio_division=10):\n",
    "    def data_augmentation_one_label(df, label=0):\n",
    "        df_label = df[df['change_type']==label]\n",
    "\n",
    "        res = []\n",
    "\n",
    "        nb_geography_types = len(geography_types)\n",
    "\n",
    "        n = len(df_label)\n",
    "        for i in range(n):\n",
    "            new_line = df_label.iloc[i]\n",
    "            for categ in ['date2', 'date3', 'date4', 'date5']:\n",
    "                new_line[categ] += (2*rd.randint(0,1)-1)*new_line[categ]/ratio_division\n",
    "            \n",
    "            if (i%ratio_geog == 0):\n",
    "                r = rd.randint(0, nb_geography_types-1)\n",
    "                new_line[geography_types[r]] = 1\n",
    "\n",
    "            res.append(new_line)\n",
    "\n",
    "        res = pd.DataFrame(res)\n",
    "        concat = pd.concat([df, res]).sample(frac = 1)\n",
    "        concat = concat.reset_index()\n",
    "        concat = concat.drop(columns=['index'])\n",
    "\n",
    "        return concat\n",
    "    \n",
    "    for label in labels:\n",
    "        df = data_augmentation_one_label(df, label)\n",
    "    \n",
    "    if 'level_0' in df.columns:\n",
    "        df = df.drop(columns=['level_0'])\n",
    "        \n",
    "    return df\n",
    "\n",
    "# df = data_augmentation(df, [0,1,1, 4,4,4,5,5,5,5], ratio_geog=10, ratio_division=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_B-KYuOz3H1h"
   },
   "source": [
    "### Separate train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "XBdrwmUP3YBZ"
   },
   "outputs": [],
   "source": [
    "y = df['change_type'].values\n",
    "X = df.drop(columns=['change_type'])\n",
    "X = X.astype('float64')\n",
    "\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIQ-3NILkPwA"
   },
   "source": [
    "# **3) Train model**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d-U_KYr-T6r"
   },
   "source": [
    "## a) Machine learning algorithms with scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-oNA0uBa3tXQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aJ5BSjMrI5EV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77631367 0.77901969 0.77435848 0.77927775 0.77790681]\n"
     ]
    }
   ],
   "source": [
    "## Train a simple OnveVsRestClassifier using featurized data\n",
    "model = RandomForestClassifier(n_estimators=100, criterion='entropy', max_features='auto')\n",
    "print(cross_val_score(model, X, y, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search\n",
    "param_grid = { \n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'criterion' :['entropy', 'gini']\n",
    "}\n",
    "\n",
    "estimator = RandomForestClassifier()\n",
    "CV_rfc = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=3)\n",
    "CV_rfc.fit(X, y)\n",
    "\n",
    "print(CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanis\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:02:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanis\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:11:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanis\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:20:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0.7807734  0.77818745 0.78020032]\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(objective=\"multi:softprob\")\n",
    "print(cross_val_score(model, X, y, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72299102 0.72361736 0.72553346]\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=50)\n",
    "print(cross_val_score(model, X, y, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66983433 0.67921808 0.67961484]\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier(n_estimators=50)\n",
    "print(cross_val_score(model, X, y, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC()\n",
    "print(cross_val_score(model, X, y, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5293    18   357   286     1     0]\n",
      " [   23  1538   484   969     0     0]\n",
      " [ 1125   113 27127  4367     3     2]\n",
      " [  569   329  6402 12661    19     0]\n",
      " [    7    11   117   147     8     0]\n",
      " [    1     0    14    11     0     0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "a = confusion_matrix(y_test, preds)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2456a1f3430>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(a, interpolation='nearest', cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQ_6SlWu-r50"
   },
   "source": [
    "## b) Deep learning with Tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "nsFUh9iNLxAl"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "kp0ntaHBdPwG"
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "  plt.plot(history.history['accuracy'])\n",
    "  plt.plot(history.history['val_accuracy'])\n",
    "  plt.title('model accuracy')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'test'], loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XLJFmJOX51w"
   },
   "source": [
    "### 1. Feedforward neural network with dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Ku7xrLPbL4VU"
   },
   "outputs": [],
   "source": [
    "class SimpleModel:\n",
    "  def __init__(self):\n",
    "    self.model = keras.Sequential()\n",
    "    self.model.add(layers.Dense(128, activation=\"relu\"))\n",
    "    # self.model.add(layers.Dropout(0.2))\n",
    "    self.model.add(layers.Dense(64, activation=\"relu\"))\n",
    "    # self.model.add(layers.Dropout(0.2))\n",
    "    self.model.add(layers.Dense(32, activation=\"relu\"))\n",
    "    self.model.add(layers.Dense(6, activation='softmax'))\n",
    "    self.model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "  def fit(self, X, y, validation_split=0, batch_size=128, epochs=5):\n",
    "    y = keras.utils.to_categorical(y, 6)\n",
    "    history = self.model.fit(X, y, validation_split=validation_split, batch_size=batch_size, epochs=epochs)\n",
    "    return history\n",
    "\n",
    "  def predict(self, X):\n",
    "    preds = self.model.predict(X)\n",
    "    res = []\n",
    "    n = len(preds)\n",
    "    for i in range(n):\n",
    "      res.append(np.argmax(preds[i]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xzl5KMapOepN",
    "outputId": "5d41a3e8-ac9e-48d6-81be-f246470c5a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 1.1007 - accuracy: 0.5894 - val_loss: 0.9037 - val_accuracy: 0.6279\n",
      "Epoch 2/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.8658 - accuracy: 0.6332 - val_loss: 0.8508 - val_accuracy: 0.6462\n",
      "Epoch 3/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.8247 - accuracy: 0.6481 - val_loss: 0.8330 - val_accuracy: 0.6494\n",
      "Epoch 4/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.7933 - accuracy: 0.6627 - val_loss: 0.8174 - val_accuracy: 0.6594\n",
      "Epoch 5/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.7479 - accuracy: 0.6807 - val_loss: 0.7729 - val_accuracy: 0.6643\n",
      "Epoch 6/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.7115 - accuracy: 0.6916 - val_loss: 0.7262 - val_accuracy: 0.6930\n",
      "Epoch 7/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.7020 - accuracy: 0.6954 - val_loss: 0.7045 - val_accuracy: 0.7014\n",
      "Epoch 8/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6933 - accuracy: 0.7003 - val_loss: 0.6962 - val_accuracy: 0.7014\n",
      "Epoch 9/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6842 - accuracy: 0.7040 - val_loss: 0.6801 - val_accuracy: 0.7102\n",
      "Epoch 10/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6788 - accuracy: 0.7056 - val_loss: 0.6777 - val_accuracy: 0.7109\n",
      "Epoch 11/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6708 - accuracy: 0.7104 - val_loss: 0.6884 - val_accuracy: 0.7020\n",
      "Epoch 12/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6661 - accuracy: 0.7128 - val_loss: 0.7145 - val_accuracy: 0.6869\n",
      "Epoch 13/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.6587 - accuracy: 0.7166 - val_loss: 0.6716 - val_accuracy: 0.7182\n",
      "Epoch 14/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.6547 - accuracy: 0.7183 - val_loss: 0.6657 - val_accuracy: 0.7161\n",
      "Epoch 15/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6497 - accuracy: 0.7205 - val_loss: 0.6814 - val_accuracy: 0.7050\n",
      "Epoch 16/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6473 - accuracy: 0.7215 - val_loss: 0.6494 - val_accuracy: 0.7247\n",
      "Epoch 17/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6430 - accuracy: 0.7239 - val_loss: 0.6482 - val_accuracy: 0.7218\n",
      "Epoch 18/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6389 - accuracy: 0.7258 - val_loss: 0.6550 - val_accuracy: 0.7230\n",
      "Epoch 19/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.6370 - accuracy: 0.7273 - val_loss: 0.6516 - val_accuracy: 0.7188\n",
      "Epoch 20/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.6348 - accuracy: 0.7282 - val_loss: 0.6518 - val_accuracy: 0.7229\n",
      "Epoch 21/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6338 - accuracy: 0.7289 - val_loss: 0.6511 - val_accuracy: 0.7260\n",
      "Epoch 22/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.6319 - accuracy: 0.7293 - val_loss: 0.6422 - val_accuracy: 0.7288\n",
      "Epoch 23/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6296 - accuracy: 0.7301 - val_loss: 0.6464 - val_accuracy: 0.7275\n",
      "Epoch 24/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6287 - accuracy: 0.7307 - val_loss: 0.6412 - val_accuracy: 0.7312\n",
      "Epoch 25/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6283 - accuracy: 0.7319 - val_loss: 0.6345 - val_accuracy: 0.7326\n",
      "Epoch 26/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6257 - accuracy: 0.7324 - val_loss: 0.6449 - val_accuracy: 0.7233\n",
      "Epoch 27/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.6254 - accuracy: 0.7324 - val_loss: 0.6361 - val_accuracy: 0.7322\n",
      "Epoch 28/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6231 - accuracy: 0.7335 - val_loss: 0.6384 - val_accuracy: 0.7326\n",
      "Epoch 29/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6218 - accuracy: 0.7344 - val_loss: 0.6305 - val_accuracy: 0.7317\n",
      "Epoch 30/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.6203 - accuracy: 0.7354 - val_loss: 0.6488 - val_accuracy: 0.7227\n",
      "Epoch 31/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6199 - accuracy: 0.7360 - val_loss: 0.6259 - val_accuracy: 0.7368\n",
      "Epoch 32/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6183 - accuracy: 0.7362 - val_loss: 0.6420 - val_accuracy: 0.7267\n",
      "Epoch 33/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.6177 - accuracy: 0.7372 - val_loss: 0.6487 - val_accuracy: 0.7232\n",
      "Epoch 34/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6202 - accuracy: 0.7356 - val_loss: 0.6377 - val_accuracy: 0.7271\n",
      "Epoch 35/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6164 - accuracy: 0.7374 - val_loss: 0.6256 - val_accuracy: 0.7379\n",
      "Epoch 36/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6172 - accuracy: 0.7375 - val_loss: 0.6390 - val_accuracy: 0.7319\n",
      "Epoch 37/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6143 - accuracy: 0.7383 - val_loss: 0.6334 - val_accuracy: 0.7348\n",
      "Epoch 38/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6136 - accuracy: 0.7394 - val_loss: 0.6314 - val_accuracy: 0.7328\n",
      "Epoch 39/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6131 - accuracy: 0.7393 - val_loss: 0.6370 - val_accuracy: 0.7311\n",
      "Epoch 40/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6131 - accuracy: 0.7389 - val_loss: 0.6424 - val_accuracy: 0.7329\n",
      "Epoch 41/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6119 - accuracy: 0.7402 - val_loss: 0.6310 - val_accuracy: 0.7335\n",
      "Epoch 42/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6117 - accuracy: 0.7399 - val_loss: 0.6278 - val_accuracy: 0.7336\n",
      "Epoch 43/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6109 - accuracy: 0.7399 - val_loss: 0.6273 - val_accuracy: 0.7387\n",
      "Epoch 44/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6099 - accuracy: 0.7400 - val_loss: 0.6240 - val_accuracy: 0.7373\n",
      "Epoch 45/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.6099 - accuracy: 0.7403 - val_loss: 0.6311 - val_accuracy: 0.7361\n",
      "Epoch 46/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6089 - accuracy: 0.7416 - val_loss: 0.6341 - val_accuracy: 0.7332\n",
      "Epoch 47/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6079 - accuracy: 0.7422 - val_loss: 0.6287 - val_accuracy: 0.7356\n",
      "Epoch 48/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6079 - accuracy: 0.7421 - val_loss: 0.6297 - val_accuracy: 0.7338\n",
      "Epoch 49/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6080 - accuracy: 0.7417 - val_loss: 0.6280 - val_accuracy: 0.7354\n",
      "Epoch 50/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6066 - accuracy: 0.7426 - val_loss: 0.6225 - val_accuracy: 0.7396\n",
      "Epoch 51/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6063 - accuracy: 0.7430 - val_loss: 0.6381 - val_accuracy: 0.7294\n",
      "Epoch 52/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6061 - accuracy: 0.7431 - val_loss: 0.6274 - val_accuracy: 0.7344\n",
      "Epoch 53/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6062 - accuracy: 0.7428 - val_loss: 0.6314 - val_accuracy: 0.7344\n",
      "Epoch 54/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6044 - accuracy: 0.7437 - val_loss: 0.6342 - val_accuracy: 0.7307\n",
      "Epoch 55/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6055 - accuracy: 0.7432 - val_loss: 0.6196 - val_accuracy: 0.7433\n",
      "Epoch 56/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6037 - accuracy: 0.7447 - val_loss: 0.6178 - val_accuracy: 0.7417\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6030 - accuracy: 0.7452 - val_loss: 0.6264 - val_accuracy: 0.7376\n",
      "Epoch 58/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.6041 - accuracy: 0.7429 - val_loss: 0.6178 - val_accuracy: 0.7420\n",
      "Epoch 59/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.6062 - accuracy: 0.7447 - val_loss: 0.6248 - val_accuracy: 0.7393\n",
      "Epoch 60/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.6059 - accuracy: 0.7436 - val_loss: 0.6290 - val_accuracy: 0.7381\n",
      "Epoch 61/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6045 - accuracy: 0.7443 - val_loss: 0.6276 - val_accuracy: 0.7383\n",
      "Epoch 62/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.6013 - accuracy: 0.7452 - val_loss: 0.6353 - val_accuracy: 0.7293\n",
      "Epoch 63/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6011 - accuracy: 0.7456 - val_loss: 0.6269 - val_accuracy: 0.7354\n",
      "Epoch 64/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6023 - accuracy: 0.7447 - val_loss: 0.6175 - val_accuracy: 0.7417\n",
      "Epoch 65/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.6003 - accuracy: 0.7459 - val_loss: 0.6293 - val_accuracy: 0.7376\n",
      "Epoch 66/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6006 - accuracy: 0.7456 - val_loss: 0.6220 - val_accuracy: 0.7389\n",
      "Epoch 67/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.6004 - accuracy: 0.7466 - val_loss: 0.6188 - val_accuracy: 0.7419\n",
      "Epoch 68/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.5993 - accuracy: 0.7462 - val_loss: 0.6367 - val_accuracy: 0.7368\n",
      "Epoch 69/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.6011 - accuracy: 0.7452 - val_loss: 0.6358 - val_accuracy: 0.7295\n",
      "Epoch 70/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.5985 - accuracy: 0.7469 - val_loss: 0.6290 - val_accuracy: 0.7354\n",
      "Epoch 71/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.5976 - accuracy: 0.7460 - val_loss: 0.6203 - val_accuracy: 0.7396\n",
      "Epoch 72/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.5987 - accuracy: 0.7468 - val_loss: 0.6215 - val_accuracy: 0.7379\n",
      "Epoch 73/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.5982 - accuracy: 0.7474 - val_loss: 0.6227 - val_accuracy: 0.7377\n",
      "Epoch 74/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.5964 - accuracy: 0.7468 - val_loss: 0.6242 - val_accuracy: 0.7367\n",
      "Epoch 75/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.5966 - accuracy: 0.7473 - val_loss: 0.6188 - val_accuracy: 0.7425\n",
      "Epoch 76/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.5987 - accuracy: 0.7465 - val_loss: 0.6265 - val_accuracy: 0.7367\n",
      "Epoch 77/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.5953 - accuracy: 0.7472 - val_loss: 0.6224 - val_accuracy: 0.7381\n",
      "Epoch 78/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.5954 - accuracy: 0.7482 - val_loss: 0.6221 - val_accuracy: 0.7367\n",
      "Epoch 79/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.5962 - accuracy: 0.7470 - val_loss: 0.6172 - val_accuracy: 0.7408\n",
      "Epoch 80/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.5973 - accuracy: 0.7478 - val_loss: 0.6176 - val_accuracy: 0.7414\n",
      "Epoch 81/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.5961 - accuracy: 0.7485 - val_loss: 0.6342 - val_accuracy: 0.7332\n",
      "Epoch 82/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.5943 - accuracy: 0.7484 - val_loss: 0.6327 - val_accuracy: 0.7332\n",
      "Epoch 83/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.5944 - accuracy: 0.7483 - val_loss: 0.6241 - val_accuracy: 0.7363\n",
      "Epoch 84/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.5940 - accuracy: 0.7488 - val_loss: 0.6194 - val_accuracy: 0.7413\n",
      "Epoch 85/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.5966 - accuracy: 0.7478 - val_loss: 0.6217 - val_accuracy: 0.7405\n",
      "Epoch 86/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.5938 - accuracy: 0.7492 - val_loss: 0.6161 - val_accuracy: 0.7415\n",
      "Epoch 87/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.5939 - accuracy: 0.7493 - val_loss: 0.6306 - val_accuracy: 0.7339\n",
      "Epoch 88/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.5931 - accuracy: 0.7500 - val_loss: 0.6287 - val_accuracy: 0.7367\n",
      "Epoch 89/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.5934 - accuracy: 0.7491 - val_loss: 0.6218 - val_accuracy: 0.7414\n",
      "Epoch 90/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.5954 - accuracy: 0.7482 - val_loss: 0.6205 - val_accuracy: 0.7397\n",
      "Epoch 91/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.5920 - accuracy: 0.7504 - val_loss: 0.6266 - val_accuracy: 0.7350\n",
      "Epoch 92/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.5934 - accuracy: 0.7490 - val_loss: 0.6284 - val_accuracy: 0.7355\n",
      "Epoch 93/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.5934 - accuracy: 0.7497 - val_loss: 0.6249 - val_accuracy: 0.7378\n",
      "Epoch 94/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.5922 - accuracy: 0.7504 - val_loss: 0.6181 - val_accuracy: 0.7443\n",
      "Epoch 95/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.5939 - accuracy: 0.7491 - val_loss: 0.6140 - val_accuracy: 0.7425\n",
      "Epoch 96/100\n",
      "1744/1744 [==============================] - 5s 3ms/step - loss: 0.5915 - accuracy: 0.7502 - val_loss: 0.6252 - val_accuracy: 0.7412\n",
      "Epoch 97/100\n",
      "1744/1744 [==============================] - 4s 2ms/step - loss: 0.5915 - accuracy: 0.7498 - val_loss: 0.6253 - val_accuracy: 0.7385\n",
      "Epoch 98/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.5922 - accuracy: 0.7494 - val_loss: 0.6275 - val_accuracy: 0.7360\n",
      "Epoch 99/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.5909 - accuracy: 0.7507 - val_loss: 0.6170 - val_accuracy: 0.7417\n",
      "Epoch 100/100\n",
      "1744/1744 [==============================] - 4s 3ms/step - loss: 0.5925 - accuracy: 0.7501 - val_loss: 0.6257 - val_accuracy: 0.7389\n"
     ]
    }
   ],
   "source": [
    "model = SimpleModel()\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_split=0.1, \n",
    "                    batch_size=128, \n",
    "                    epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "7GPuhuCuj-Sk",
    "outputId": "8513ca47-8faf-42a8-a813-303e36020f74"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uRKYD8IIQWd3",
    "outputId": "2f719c2b-f7bc-48f9-a525-7aacea351d03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7390084190832554\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "print(accuracy_score(preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bagging of neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "B_W3jeWktBPK"
   },
   "outputs": [],
   "source": [
    "class Bagging:\n",
    "  def __init__(self):\n",
    "    self.list_models = []\n",
    "\n",
    "  def most_frequent(self, List):\n",
    "    return max(set(List), key = List.count)\n",
    "  \n",
    "  def fit(self, X, y, validation_split=0, batch_size=128, epochs=5):\n",
    "    i = 1\n",
    "    n = len(self.list_models)\n",
    "    m = len(X)\n",
    "    for i in range(n):\n",
    "      print(\"Entrainement du numéro \" + str(i+1) + \"/\" + str(n))\n",
    "      step = m/n\n",
    "      borne_inf = int(i*step)\n",
    "      borne_sup = int((i+1)*step)\n",
    "      self.list_models[i].fit(X[borne_inf:borne_sup], y[borne_inf:borne_sup], validation_split=validation_split, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "  def predict(self, X):\n",
    "    preds = np.array([model.predict(X) for model in self.list_models])\n",
    "    n = len(preds)\n",
    "    m = len(self.list_models)\n",
    "\n",
    "    (nb_model, nb) = preds.shape\n",
    "    res = []\n",
    "    for i in range(nb):\n",
    "      final_preds = self.most_frequent([preds[j][i] for j in range(nb_model)])\n",
    "      res.append(final_preds)\n",
    "\n",
    "    return res\n",
    "\n",
    "  def add_model(self):\n",
    "    model = SimpleModel()\n",
    "    self.list_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "OGr-KuUevC6L"
   },
   "outputs": [],
   "source": [
    "global_model = Bagging()\n",
    "for i in range(11):\n",
    "  global_model.add_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrB_62pXvpp6",
    "outputId": "449c5f3f-e2b3-464b-de0d-ff44985d3b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement du numéro 1/11\n",
      "Epoch 1/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 6.0032 - accuracy: 0.4906 - val_loss: 1.2103 - val_accuracy: 0.5353\n",
      "Epoch 2/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.0896 - accuracy: 0.5761 - val_loss: 1.1003 - val_accuracy: 0.5534\n",
      "Epoch 3/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.0272 - accuracy: 0.5884 - val_loss: 1.1048 - val_accuracy: 0.5357\n",
      "Epoch 4/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9857 - accuracy: 0.5902 - val_loss: 1.0058 - val_accuracy: 0.5827\n",
      "Epoch 5/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9913 - accuracy: 0.5933 - val_loss: 1.0896 - val_accuracy: 0.5605\n",
      "Epoch 6/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9489 - accuracy: 0.6104 - val_loss: 1.0050 - val_accuracy: 0.5747\n",
      "Epoch 7/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9710 - accuracy: 0.5968 - val_loss: 1.0010 - val_accuracy: 0.5716\n",
      "Epoch 8/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9206 - accuracy: 0.6129 - val_loss: 0.9518 - val_accuracy: 0.6000\n",
      "Epoch 9/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9220 - accuracy: 0.6107 - val_loss: 1.0333 - val_accuracy: 0.5721\n",
      "Epoch 10/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9079 - accuracy: 0.6160 - val_loss: 0.9566 - val_accuracy: 0.5889\n",
      "Epoch 11/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8856 - accuracy: 0.6246 - val_loss: 0.9835 - val_accuracy: 0.5783\n",
      "Epoch 12/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8923 - accuracy: 0.6171 - val_loss: 0.9193 - val_accuracy: 0.6248\n",
      "Epoch 13/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8688 - accuracy: 0.6252 - val_loss: 0.9178 - val_accuracy: 0.6053\n",
      "Epoch 14/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8639 - accuracy: 0.6269 - val_loss: 0.9210 - val_accuracy: 0.5925\n",
      "Epoch 15/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8475 - accuracy: 0.6339 - val_loss: 0.8802 - val_accuracy: 0.6137\n",
      "Epoch 16/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8337 - accuracy: 0.6417 - val_loss: 0.8608 - val_accuracy: 0.6359\n",
      "Epoch 17/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8419 - accuracy: 0.6335 - val_loss: 0.8506 - val_accuracy: 0.6355\n",
      "Epoch 18/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8329 - accuracy: 0.6406 - val_loss: 0.8773 - val_accuracy: 0.6204\n",
      "Epoch 19/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8005 - accuracy: 0.6534 - val_loss: 0.8821 - val_accuracy: 0.6275\n",
      "Epoch 20/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8134 - accuracy: 0.6422 - val_loss: 0.8650 - val_accuracy: 0.6297\n",
      "Epoch 21/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7937 - accuracy: 0.6586 - val_loss: 0.8108 - val_accuracy: 0.6585\n",
      "Epoch 22/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7792 - accuracy: 0.6609 - val_loss: 0.8512 - val_accuracy: 0.6359\n",
      "Epoch 23/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7804 - accuracy: 0.6631 - val_loss: 0.8420 - val_accuracy: 0.6426\n",
      "Epoch 24/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7666 - accuracy: 0.6681 - val_loss: 0.8322 - val_accuracy: 0.6373\n",
      "Epoch 25/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.7516 - accuracy: 0.6756 - val_loss: 0.8307 - val_accuracy: 0.6501\n",
      "Epoch 26/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7590 - accuracy: 0.6737 - val_loss: 0.7996 - val_accuracy: 0.6603\n",
      "Epoch 27/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7571 - accuracy: 0.6713 - val_loss: 0.7831 - val_accuracy: 0.6692\n",
      "Epoch 28/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7467 - accuracy: 0.6734 - val_loss: 0.8090 - val_accuracy: 0.6461\n",
      "Epoch 29/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.6785 - val_loss: 0.7964 - val_accuracy: 0.6647\n",
      "Epoch 30/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7431 - accuracy: 0.6799 - val_loss: 0.7757 - val_accuracy: 0.6665\n",
      "Epoch 31/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7295 - accuracy: 0.6834 - val_loss: 0.7986 - val_accuracy: 0.6687\n",
      "Epoch 32/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7287 - accuracy: 0.6851 - val_loss: 0.8057 - val_accuracy: 0.6514\n",
      "Epoch 33/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7341 - accuracy: 0.6766 - val_loss: 0.8112 - val_accuracy: 0.6501\n",
      "Epoch 34/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7312 - accuracy: 0.6826 - val_loss: 0.8001 - val_accuracy: 0.6590\n",
      "Epoch 35/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7295 - accuracy: 0.6812 - val_loss: 0.7663 - val_accuracy: 0.6754\n",
      "Epoch 36/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7242 - accuracy: 0.6825 - val_loss: 0.7914 - val_accuracy: 0.6585\n",
      "Epoch 37/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7233 - accuracy: 0.6850 - val_loss: 0.7741 - val_accuracy: 0.6692\n",
      "Epoch 38/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7151 - accuracy: 0.6902 - val_loss: 0.7807 - val_accuracy: 0.6789\n",
      "Epoch 39/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7132 - accuracy: 0.6917 - val_loss: 0.7822 - val_accuracy: 0.6696\n",
      "Epoch 40/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7213 - accuracy: 0.6859 - val_loss: 0.7683 - val_accuracy: 0.6736\n",
      "Epoch 41/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7047 - accuracy: 0.6911 - val_loss: 0.7987 - val_accuracy: 0.6705\n",
      "Epoch 42/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7171 - accuracy: 0.6873 - val_loss: 0.7853 - val_accuracy: 0.6772\n",
      "Epoch 43/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7186 - accuracy: 0.6900 - val_loss: 0.7851 - val_accuracy: 0.6674\n",
      "Epoch 44/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7117 - accuracy: 0.6900 - val_loss: 0.7751 - val_accuracy: 0.6749\n",
      "Epoch 45/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7022 - accuracy: 0.6926 - val_loss: 0.7604 - val_accuracy: 0.6803\n",
      "Epoch 46/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7028 - accuracy: 0.6946 - val_loss: 0.7630 - val_accuracy: 0.6794\n",
      "Epoch 47/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.6998 - accuracy: 0.6938 - val_loss: 0.7714 - val_accuracy: 0.6763\n",
      "Epoch 48/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7110 - accuracy: 0.6887 - val_loss: 0.7674 - val_accuracy: 0.6794\n",
      "Epoch 49/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.6957 - accuracy: 0.6986 - val_loss: 0.8400 - val_accuracy: 0.6656\n",
      "Epoch 50/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7040 - accuracy: 0.6911 - val_loss: 0.7806 - val_accuracy: 0.6705\n",
      "Entrainement du numéro 2/11\n",
      "Epoch 1/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 6.4649 - accuracy: 0.4858 - val_loss: 1.4234 - val_accuracy: 0.5481\n",
      "Epoch 2/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.3387 - accuracy: 0.5611 - val_loss: 1.2033 - val_accuracy: 0.5800\n",
      "Epoch 3/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.2283 - accuracy: 0.5711 - val_loss: 1.3326 - val_accuracy: 0.5743\n",
      "Epoch 4/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.1237 - accuracy: 0.5810 - val_loss: 1.0763 - val_accuracy: 0.5947\n",
      "Epoch 5/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.0738 - accuracy: 0.5904 - val_loss: 1.0747 - val_accuracy: 0.5969\n",
      "Epoch 6/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.0259 - accuracy: 0.5990 - val_loss: 1.0606 - val_accuracy: 0.5525\n",
      "Epoch 7/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9549 - accuracy: 0.6119 - val_loss: 1.1039 - val_accuracy: 0.5490\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9752 - accuracy: 0.6124 - val_loss: 0.9518 - val_accuracy: 0.6124\n",
      "Epoch 9/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9300 - accuracy: 0.6226 - val_loss: 0.9560 - val_accuracy: 0.6044\n",
      "Epoch 10/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9099 - accuracy: 0.6274 - val_loss: 0.9818 - val_accuracy: 0.6124\n",
      "Epoch 11/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9524 - accuracy: 0.6144 - val_loss: 0.8951 - val_accuracy: 0.6319\n",
      "Epoch 12/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9370 - accuracy: 0.6228 - val_loss: 0.9302 - val_accuracy: 0.6142\n",
      "Epoch 13/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8775 - accuracy: 0.6345 - val_loss: 0.9258 - val_accuracy: 0.6129\n",
      "Epoch 14/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8949 - accuracy: 0.6347 - val_loss: 0.8703 - val_accuracy: 0.6239\n",
      "Epoch 15/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8938 - accuracy: 0.6294 - val_loss: 0.8819 - val_accuracy: 0.6364\n",
      "Epoch 16/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9330 - accuracy: 0.6183 - val_loss: 0.9557 - val_accuracy: 0.6049\n",
      "Epoch 17/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9117 - accuracy: 0.6266 - val_loss: 0.8607 - val_accuracy: 0.6315\n",
      "Epoch 18/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8687 - accuracy: 0.6440 - val_loss: 0.9008 - val_accuracy: 0.6368\n",
      "Epoch 19/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8646 - accuracy: 0.6410 - val_loss: 0.8597 - val_accuracy: 0.6443\n",
      "Epoch 20/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8474 - accuracy: 0.6431 - val_loss: 0.9747 - val_accuracy: 0.6164\n",
      "Epoch 21/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8358 - accuracy: 0.6505 - val_loss: 0.8300 - val_accuracy: 0.6559\n",
      "Epoch 22/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8431 - accuracy: 0.6493 - val_loss: 0.8713 - val_accuracy: 0.6288\n",
      "Epoch 23/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8242 - accuracy: 0.6528 - val_loss: 1.0428 - val_accuracy: 0.5694\n",
      "Epoch 24/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8400 - accuracy: 0.6492 - val_loss: 0.8626 - val_accuracy: 0.6222\n",
      "Epoch 25/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8259 - accuracy: 0.6548 - val_loss: 0.9119 - val_accuracy: 0.6257\n",
      "Epoch 26/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8352 - accuracy: 0.6533 - val_loss: 0.8430 - val_accuracy: 0.6537\n",
      "Epoch 27/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8257 - accuracy: 0.6528 - val_loss: 0.8451 - val_accuracy: 0.6421\n",
      "Epoch 28/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8130 - accuracy: 0.6527 - val_loss: 0.8323 - val_accuracy: 0.6576\n",
      "Epoch 29/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8300 - accuracy: 0.6554 - val_loss: 0.8432 - val_accuracy: 0.6399\n",
      "Epoch 30/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8235 - accuracy: 0.6490 - val_loss: 0.9494 - val_accuracy: 0.6022\n",
      "Epoch 31/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8261 - accuracy: 0.6519 - val_loss: 0.8582 - val_accuracy: 0.6275\n",
      "Epoch 32/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8234 - accuracy: 0.6517 - val_loss: 0.8275 - val_accuracy: 0.6466\n",
      "Epoch 33/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8271 - accuracy: 0.6509 - val_loss: 0.9242 - val_accuracy: 0.6315\n",
      "Epoch 34/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7955 - accuracy: 0.6615 - val_loss: 0.8276 - val_accuracy: 0.6483\n",
      "Epoch 35/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8034 - accuracy: 0.6629 - val_loss: 0.9030 - val_accuracy: 0.6262\n",
      "Epoch 36/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7999 - accuracy: 0.6605 - val_loss: 0.8364 - val_accuracy: 0.6355\n",
      "Epoch 37/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8007 - accuracy: 0.6593 - val_loss: 0.8412 - val_accuracy: 0.6475\n",
      "Epoch 38/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7951 - accuracy: 0.6604 - val_loss: 0.8639 - val_accuracy: 0.6514\n",
      "Epoch 39/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7974 - accuracy: 0.6608 - val_loss: 0.8661 - val_accuracy: 0.6457\n",
      "Epoch 40/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8019 - accuracy: 0.6617 - val_loss: 0.8188 - val_accuracy: 0.6492\n",
      "Epoch 41/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7722 - accuracy: 0.6743 - val_loss: 0.7996 - val_accuracy: 0.6568\n",
      "Epoch 42/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7846 - accuracy: 0.6684 - val_loss: 0.8637 - val_accuracy: 0.6501\n",
      "Epoch 43/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.7864 - accuracy: 0.6697 - val_loss: 0.8203 - val_accuracy: 0.6550\n",
      "Epoch 44/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7828 - accuracy: 0.6654 - val_loss: 0.8176 - val_accuracy: 0.6639\n",
      "Epoch 45/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7899 - accuracy: 0.6609 - val_loss: 0.8202 - val_accuracy: 0.6470\n",
      "Epoch 46/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7824 - accuracy: 0.6628 - val_loss: 0.8032 - val_accuracy: 0.6457\n",
      "Epoch 47/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7837 - accuracy: 0.6653 - val_loss: 0.8752 - val_accuracy: 0.6124\n",
      "Epoch 48/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7668 - accuracy: 0.6777 - val_loss: 0.7782 - val_accuracy: 0.6714\n",
      "Epoch 49/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7571 - accuracy: 0.6758 - val_loss: 0.7992 - val_accuracy: 0.6643\n",
      "Epoch 50/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7782 - accuracy: 0.6644 - val_loss: 0.9040 - val_accuracy: 0.5965\n",
      "Entrainement du numéro 3/11\n",
      "Epoch 1/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 3.3638 - accuracy: 0.4938 - val_loss: 1.5847 - val_accuracy: 0.4865\n",
      "Epoch 2/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 1.3275 - accuracy: 0.5537 - val_loss: 1.1948 - val_accuracy: 0.5911\n",
      "Epoch 3/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 1.1947 - accuracy: 0.5729 - val_loss: 1.2860 - val_accuracy: 0.5929\n",
      "Epoch 4/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 1.1224 - accuracy: 0.5856 - val_loss: 1.2875 - val_accuracy: 0.5738\n",
      "Epoch 5/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 1.0861 - accuracy: 0.5795 - val_loss: 1.1958 - val_accuracy: 0.5561\n",
      "Epoch 6/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 1.0975 - accuracy: 0.5831 - val_loss: 1.1257 - val_accuracy: 0.6169\n",
      "Epoch 7/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9633 - accuracy: 0.6026 - val_loss: 1.1346 - val_accuracy: 0.6155\n",
      "Epoch 8/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9965 - accuracy: 0.6053 - val_loss: 1.1361 - val_accuracy: 0.5982\n",
      "Epoch 9/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9823 - accuracy: 0.6135 - val_loss: 1.1052 - val_accuracy: 0.6306\n",
      "Epoch 10/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9806 - accuracy: 0.6114 - val_loss: 1.2002 - val_accuracy: 0.5942\n",
      "Epoch 11/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9737 - accuracy: 0.5977 - val_loss: 0.9227 - val_accuracy: 0.6435\n",
      "Epoch 12/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9079 - accuracy: 0.6166 - val_loss: 0.9388 - val_accuracy: 0.6244\n",
      "Epoch 13/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8696 - accuracy: 0.6309 - val_loss: 1.0437 - val_accuracy: 0.6284\n",
      "Epoch 14/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9620 - accuracy: 0.6153 - val_loss: 0.9525 - val_accuracy: 0.6124\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8899 - accuracy: 0.6299 - val_loss: 1.2836 - val_accuracy: 0.6071\n",
      "Epoch 16/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9004 - accuracy: 0.6214 - val_loss: 1.0848 - val_accuracy: 0.5854\n",
      "Epoch 17/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8995 - accuracy: 0.6272 - val_loss: 0.9904 - val_accuracy: 0.6364\n",
      "Epoch 18/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8719 - accuracy: 0.6266 - val_loss: 1.0025 - val_accuracy: 0.5654\n",
      "Epoch 19/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8301 - accuracy: 0.6444 - val_loss: 0.9366 - val_accuracy: 0.6483\n",
      "Epoch 20/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8800 - accuracy: 0.6373 - val_loss: 0.8897 - val_accuracy: 0.6302\n",
      "Epoch 21/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8775 - accuracy: 0.6351 - val_loss: 0.9115 - val_accuracy: 0.6364\n",
      "Epoch 22/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8442 - accuracy: 0.6421 - val_loss: 1.0228 - val_accuracy: 0.6421\n",
      "Epoch 23/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8559 - accuracy: 0.6421 - val_loss: 0.9012 - val_accuracy: 0.6408\n",
      "Epoch 24/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8339 - accuracy: 0.6482 - val_loss: 0.9147 - val_accuracy: 0.6208\n",
      "Epoch 25/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8171 - accuracy: 0.6500 - val_loss: 0.9425 - val_accuracy: 0.6457\n",
      "Epoch 26/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8453 - accuracy: 0.6429 - val_loss: 0.8513 - val_accuracy: 0.6466\n",
      "Epoch 27/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8213 - accuracy: 0.6484 - val_loss: 0.8581 - val_accuracy: 0.6399\n",
      "Epoch 28/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8091 - accuracy: 0.6504 - val_loss: 0.8315 - val_accuracy: 0.6532\n",
      "Epoch 29/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8047 - accuracy: 0.6548 - val_loss: 0.8502 - val_accuracy: 0.6399\n",
      "Epoch 30/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8018 - accuracy: 0.6539 - val_loss: 0.8202 - val_accuracy: 0.6776\n",
      "Epoch 31/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7960 - accuracy: 0.6619 - val_loss: 0.8498 - val_accuracy: 0.6625\n",
      "Epoch 32/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8035 - accuracy: 0.6535 - val_loss: 0.8315 - val_accuracy: 0.6603\n",
      "Epoch 33/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7869 - accuracy: 0.6606 - val_loss: 0.8156 - val_accuracy: 0.6741\n",
      "Epoch 34/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7824 - accuracy: 0.6665 - val_loss: 0.8229 - val_accuracy: 0.6670\n",
      "Epoch 35/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7883 - accuracy: 0.6623 - val_loss: 0.8926 - val_accuracy: 0.6443\n",
      "Epoch 36/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7863 - accuracy: 0.6655 - val_loss: 0.8163 - val_accuracy: 0.6608\n",
      "Epoch 37/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7748 - accuracy: 0.6663 - val_loss: 0.8026 - val_accuracy: 0.6576\n",
      "Epoch 38/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7697 - accuracy: 0.6672 - val_loss: 0.8953 - val_accuracy: 0.6767\n",
      "Epoch 39/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.7669 - accuracy: 0.6760 - val_loss: 0.8352 - val_accuracy: 0.6692\n",
      "Epoch 40/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7734 - accuracy: 0.6655 - val_loss: 0.8453 - val_accuracy: 0.6608\n",
      "Epoch 41/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7899 - accuracy: 0.6674 - val_loss: 0.8537 - val_accuracy: 0.6701\n",
      "Epoch 42/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7792 - accuracy: 0.6669 - val_loss: 0.8280 - val_accuracy: 0.6687\n",
      "Epoch 43/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7572 - accuracy: 0.6740 - val_loss: 0.8274 - val_accuracy: 0.6519\n",
      "Epoch 44/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7415 - accuracy: 0.6803 - val_loss: 0.7824 - val_accuracy: 0.6807\n",
      "Epoch 45/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7734 - accuracy: 0.6736 - val_loss: 0.8459 - val_accuracy: 0.6599\n",
      "Epoch 46/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7504 - accuracy: 0.6794 - val_loss: 0.8135 - val_accuracy: 0.6829\n",
      "Epoch 47/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.6807 - val_loss: 0.8009 - val_accuracy: 0.6807\n",
      "Epoch 48/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7315 - accuracy: 0.6809 - val_loss: 0.7713 - val_accuracy: 0.6763\n",
      "Epoch 49/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7286 - accuracy: 0.6842 - val_loss: 0.7946 - val_accuracy: 0.6754\n",
      "Epoch 50/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7179 - accuracy: 0.6868 - val_loss: 0.7709 - val_accuracy: 0.6789\n",
      "Entrainement du numéro 4/11\n",
      "Epoch 1/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 5.3164 - accuracy: 0.4971 - val_loss: 1.2601 - val_accuracy: 0.5268\n",
      "Epoch 2/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 1.3128 - accuracy: 0.5557 - val_loss: 1.4785 - val_accuracy: 0.4683\n",
      "Epoch 3/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.1938 - accuracy: 0.5694 - val_loss: 1.1718 - val_accuracy: 0.5743\n",
      "Epoch 4/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.0582 - accuracy: 0.5911 - val_loss: 1.1510 - val_accuracy: 0.5743\n",
      "Epoch 5/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.0416 - accuracy: 0.5908 - val_loss: 1.0730 - val_accuracy: 0.5823\n",
      "Epoch 6/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.0152 - accuracy: 0.5981 - val_loss: 1.0673 - val_accuracy: 0.5818\n",
      "Epoch 7/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.0005 - accuracy: 0.5942 - val_loss: 0.9677 - val_accuracy: 0.6115\n",
      "Epoch 8/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.0103 - accuracy: 0.6011 - val_loss: 0.9231 - val_accuracy: 0.6284\n",
      "Epoch 9/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9221 - accuracy: 0.6170 - val_loss: 1.0033 - val_accuracy: 0.6009\n",
      "Epoch 10/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9700 - accuracy: 0.6064 - val_loss: 0.9864 - val_accuracy: 0.6018\n",
      "Epoch 11/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9019 - accuracy: 0.6250 - val_loss: 0.9085 - val_accuracy: 0.6364\n",
      "Epoch 12/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9377 - accuracy: 0.6147 - val_loss: 0.9429 - val_accuracy: 0.6399\n",
      "Epoch 13/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9187 - accuracy: 0.6245 - val_loss: 0.8991 - val_accuracy: 0.6443\n",
      "Epoch 14/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8950 - accuracy: 0.6272 - val_loss: 0.9202 - val_accuracy: 0.6359\n",
      "Epoch 15/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8686 - accuracy: 0.6384 - val_loss: 0.9046 - val_accuracy: 0.6359\n",
      "Epoch 16/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8623 - accuracy: 0.6340 - val_loss: 0.9324 - val_accuracy: 0.6373\n",
      "Epoch 17/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8837 - accuracy: 0.6272 - val_loss: 0.9834 - val_accuracy: 0.6297\n",
      "Epoch 18/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8750 - accuracy: 0.6363 - val_loss: 0.8865 - val_accuracy: 0.6395\n",
      "Epoch 19/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8757 - accuracy: 0.6322 - val_loss: 0.9617 - val_accuracy: 0.6044\n",
      "Epoch 20/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8841 - accuracy: 0.6281 - val_loss: 0.9004 - val_accuracy: 0.6310\n",
      "Epoch 21/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8800 - accuracy: 0.6300 - val_loss: 0.9424 - val_accuracy: 0.6306\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8496 - accuracy: 0.6395 - val_loss: 0.8622 - val_accuracy: 0.6621\n",
      "Epoch 23/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8290 - accuracy: 0.6495 - val_loss: 0.9048 - val_accuracy: 0.6417\n",
      "Epoch 24/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8491 - accuracy: 0.6443 - val_loss: 1.0696 - val_accuracy: 0.5885\n",
      "Epoch 25/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8434 - accuracy: 0.6435 - val_loss: 0.8719 - val_accuracy: 0.6568\n",
      "Epoch 26/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8256 - accuracy: 0.6513 - val_loss: 0.8662 - val_accuracy: 0.6355\n",
      "Epoch 27/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8232 - accuracy: 0.6524 - val_loss: 0.8860 - val_accuracy: 0.6497\n",
      "Epoch 28/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8265 - accuracy: 0.6474 - val_loss: 0.8927 - val_accuracy: 0.6248\n",
      "Epoch 29/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8050 - accuracy: 0.6577 - val_loss: 0.8874 - val_accuracy: 0.6346\n",
      "Epoch 30/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8243 - accuracy: 0.6540 - val_loss: 0.9089 - val_accuracy: 0.6341\n",
      "Epoch 31/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8276 - accuracy: 0.6489 - val_loss: 0.8411 - val_accuracy: 0.6701\n",
      "Epoch 32/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8104 - accuracy: 0.6564 - val_loss: 0.8745 - val_accuracy: 0.6328\n",
      "Epoch 33/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8106 - accuracy: 0.6529 - val_loss: 0.8372 - val_accuracy: 0.6652\n",
      "Epoch 34/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8108 - accuracy: 0.6547 - val_loss: 0.8547 - val_accuracy: 0.6421\n",
      "Epoch 35/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7931 - accuracy: 0.6608 - val_loss: 0.8720 - val_accuracy: 0.6355\n",
      "Epoch 36/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7802 - accuracy: 0.6673 - val_loss: 0.8337 - val_accuracy: 0.6661\n",
      "Epoch 37/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7786 - accuracy: 0.6693 - val_loss: 0.8487 - val_accuracy: 0.6603\n",
      "Epoch 38/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7947 - accuracy: 0.6598 - val_loss: 0.8236 - val_accuracy: 0.6506\n",
      "Epoch 39/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7899 - accuracy: 0.6616 - val_loss: 0.8844 - val_accuracy: 0.6333\n",
      "Epoch 40/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7810 - accuracy: 0.6629 - val_loss: 0.8390 - val_accuracy: 0.6523\n",
      "Epoch 41/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7813 - accuracy: 0.6666 - val_loss: 0.8701 - val_accuracy: 0.6306\n",
      "Epoch 42/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7735 - accuracy: 0.6724 - val_loss: 0.8259 - val_accuracy: 0.6639\n",
      "Epoch 43/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7801 - accuracy: 0.6669 - val_loss: 0.8694 - val_accuracy: 0.6355\n",
      "Epoch 44/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7786 - accuracy: 0.6690 - val_loss: 0.8230 - val_accuracy: 0.6723\n",
      "Epoch 45/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7803 - accuracy: 0.6691 - val_loss: 0.8587 - val_accuracy: 0.6576\n",
      "Epoch 46/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7787 - accuracy: 0.6704 - val_loss: 0.8376 - val_accuracy: 0.6488\n",
      "Epoch 47/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7791 - accuracy: 0.6677 - val_loss: 0.8316 - val_accuracy: 0.6479\n",
      "Epoch 48/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7613 - accuracy: 0.6775 - val_loss: 0.8880 - val_accuracy: 0.6297\n",
      "Epoch 49/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7667 - accuracy: 0.6722 - val_loss: 0.8327 - val_accuracy: 0.6541\n",
      "Epoch 50/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7662 - accuracy: 0.6759 - val_loss: 0.8214 - val_accuracy: 0.6714\n",
      "Entrainement du numéro 5/11\n",
      "Epoch 1/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 7.4912 - accuracy: 0.4676 - val_loss: 1.3106 - val_accuracy: 0.5503\n",
      "Epoch 2/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.1028 - accuracy: 0.5647 - val_loss: 1.0729 - val_accuracy: 0.5978\n",
      "Epoch 3/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.0308 - accuracy: 0.5829 - val_loss: 1.0442 - val_accuracy: 0.5672\n",
      "Epoch 4/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 1.0063 - accuracy: 0.5858 - val_loss: 1.1045 - val_accuracy: 0.5627\n",
      "Epoch 5/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.9618 - accuracy: 0.6023 - val_loss: 1.0018 - val_accuracy: 0.6031\n",
      "Epoch 6/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9925 - accuracy: 0.5924 - val_loss: 0.9562 - val_accuracy: 0.5929\n",
      "Epoch 7/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.0423 - accuracy: 0.5761 - val_loss: 1.2197 - val_accuracy: 0.5446\n",
      "Epoch 8/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9748 - accuracy: 0.5995 - val_loss: 1.3854 - val_accuracy: 0.4443\n",
      "Epoch 9/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9746 - accuracy: 0.5996 - val_loss: 1.0033 - val_accuracy: 0.5743\n",
      "Epoch 10/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9154 - accuracy: 0.6110 - val_loss: 0.9663 - val_accuracy: 0.6137\n",
      "Epoch 11/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9504 - accuracy: 0.6071 - val_loss: 0.8979 - val_accuracy: 0.6364\n",
      "Epoch 12/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8854 - accuracy: 0.6219 - val_loss: 0.8925 - val_accuracy: 0.6381\n",
      "Epoch 13/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9061 - accuracy: 0.6128 - val_loss: 0.9971 - val_accuracy: 0.5774\n",
      "Epoch 14/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8792 - accuracy: 0.6290 - val_loss: 0.9150 - val_accuracy: 0.5956\n",
      "Epoch 15/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9210 - accuracy: 0.6131 - val_loss: 1.0488 - val_accuracy: 0.5792\n",
      "Epoch 16/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8638 - accuracy: 0.6284 - val_loss: 1.0189 - val_accuracy: 0.5707\n",
      "Epoch 17/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9027 - accuracy: 0.6147 - val_loss: 0.8836 - val_accuracy: 0.6102\n",
      "Epoch 18/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8538 - accuracy: 0.6351 - val_loss: 0.8956 - val_accuracy: 0.6080\n",
      "Epoch 19/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8709 - accuracy: 0.6277 - val_loss: 0.9878 - val_accuracy: 0.6035\n",
      "Epoch 20/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8728 - accuracy: 0.6267 - val_loss: 0.8875 - val_accuracy: 0.6497\n",
      "Epoch 21/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8652 - accuracy: 0.6300 - val_loss: 0.9264 - val_accuracy: 0.6377\n",
      "Epoch 22/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8710 - accuracy: 0.6279 - val_loss: 0.8991 - val_accuracy: 0.6253\n",
      "Epoch 23/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8359 - accuracy: 0.6403 - val_loss: 0.9558 - val_accuracy: 0.6262\n",
      "Epoch 24/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8683 - accuracy: 0.6326 - val_loss: 0.8689 - val_accuracy: 0.6350\n",
      "Epoch 25/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8204 - accuracy: 0.6459 - val_loss: 0.9102 - val_accuracy: 0.6244\n",
      "Epoch 26/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8306 - accuracy: 0.6430 - val_loss: 0.8922 - val_accuracy: 0.6519\n",
      "Epoch 27/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8253 - accuracy: 0.6450 - val_loss: 0.9272 - val_accuracy: 0.5947\n",
      "Epoch 28/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8405 - accuracy: 0.6393 - val_loss: 0.9050 - val_accuracy: 0.6155\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8239 - accuracy: 0.6466 - val_loss: 0.8473 - val_accuracy: 0.6576\n",
      "Epoch 30/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8169 - accuracy: 0.6474 - val_loss: 0.8578 - val_accuracy: 0.6528\n",
      "Epoch 31/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8213 - accuracy: 0.6417 - val_loss: 0.8375 - val_accuracy: 0.6399\n",
      "Epoch 32/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8237 - accuracy: 0.6442 - val_loss: 1.0009 - val_accuracy: 0.5836\n",
      "Epoch 33/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8140 - accuracy: 0.6475 - val_loss: 0.8503 - val_accuracy: 0.6452\n",
      "Epoch 34/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8026 - accuracy: 0.6480 - val_loss: 0.8436 - val_accuracy: 0.6417\n",
      "Epoch 35/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7937 - accuracy: 0.6571 - val_loss: 0.8665 - val_accuracy: 0.6479\n",
      "Epoch 36/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7943 - accuracy: 0.6545 - val_loss: 0.8682 - val_accuracy: 0.6448\n",
      "Epoch 37/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7776 - accuracy: 0.6651 - val_loss: 0.8468 - val_accuracy: 0.6656\n",
      "Epoch 38/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8134 - accuracy: 0.6510 - val_loss: 0.8646 - val_accuracy: 0.6346\n",
      "Epoch 39/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7897 - accuracy: 0.6565 - val_loss: 0.8420 - val_accuracy: 0.6506\n",
      "Epoch 40/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7828 - accuracy: 0.6627 - val_loss: 0.8677 - val_accuracy: 0.6594\n",
      "Epoch 41/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7732 - accuracy: 0.6638 - val_loss: 0.8289 - val_accuracy: 0.6532\n",
      "Epoch 42/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7732 - accuracy: 0.6693 - val_loss: 0.8438 - val_accuracy: 0.6483\n",
      "Epoch 43/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7849 - accuracy: 0.6576 - val_loss: 0.8251 - val_accuracy: 0.6470\n",
      "Epoch 44/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7741 - accuracy: 0.6641 - val_loss: 0.8080 - val_accuracy: 0.6634\n",
      "Epoch 45/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7729 - accuracy: 0.6650 - val_loss: 0.8981 - val_accuracy: 0.6408\n",
      "Epoch 46/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7743 - accuracy: 0.6643 - val_loss: 0.8484 - val_accuracy: 0.6195\n",
      "Epoch 47/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7590 - accuracy: 0.6722 - val_loss: 0.8293 - val_accuracy: 0.6687\n",
      "Epoch 48/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7743 - accuracy: 0.6684 - val_loss: 0.8361 - val_accuracy: 0.6319\n",
      "Epoch 49/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7677 - accuracy: 0.6687 - val_loss: 0.8434 - val_accuracy: 0.6741\n",
      "Epoch 50/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.7668 - accuracy: 0.6679 - val_loss: 0.8082 - val_accuracy: 0.6763\n",
      "Entrainement du numéro 6/11\n",
      "Epoch 1/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 3.5701 - accuracy: 0.5138 - val_loss: 1.5144 - val_accuracy: 0.4701\n",
      "Epoch 2/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.2895 - accuracy: 0.5523 - val_loss: 1.8633 - val_accuracy: 0.5685\n",
      "Epoch 3/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.1956 - accuracy: 0.5689 - val_loss: 1.3252 - val_accuracy: 0.5933\n",
      "Epoch 4/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.0853 - accuracy: 0.5904 - val_loss: 1.0606 - val_accuracy: 0.5752\n",
      "Epoch 5/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.0295 - accuracy: 0.5992 - val_loss: 1.0026 - val_accuracy: 0.6169\n",
      "Epoch 6/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.0630 - accuracy: 0.5923 - val_loss: 1.1708 - val_accuracy: 0.6217\n",
      "Epoch 7/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.0527 - accuracy: 0.5984 - val_loss: 1.0316 - val_accuracy: 0.5885\n",
      "Epoch 8/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.0244 - accuracy: 0.6066 - val_loss: 0.9525 - val_accuracy: 0.6337\n",
      "Epoch 9/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9776 - accuracy: 0.6143 - val_loss: 0.9230 - val_accuracy: 0.6421\n",
      "Epoch 10/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9327 - accuracy: 0.6233 - val_loss: 0.9260 - val_accuracy: 0.6461\n",
      "Epoch 11/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8975 - accuracy: 0.6298 - val_loss: 1.0158 - val_accuracy: 0.6155\n",
      "Epoch 12/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9780 - accuracy: 0.6132 - val_loss: 0.9138 - val_accuracy: 0.6359\n",
      "Epoch 13/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9307 - accuracy: 0.6241 - val_loss: 1.0297 - val_accuracy: 0.6040\n",
      "Epoch 14/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9273 - accuracy: 0.6201 - val_loss: 0.8937 - val_accuracy: 0.6430\n",
      "Epoch 15/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9029 - accuracy: 0.6289 - val_loss: 1.1745 - val_accuracy: 0.5361\n",
      "Epoch 16/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8819 - accuracy: 0.6322 - val_loss: 0.8759 - val_accuracy: 0.6466\n",
      "Epoch 17/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8564 - accuracy: 0.6470 - val_loss: 0.8869 - val_accuracy: 0.6519\n",
      "Epoch 18/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8972 - accuracy: 0.6321 - val_loss: 0.8623 - val_accuracy: 0.6630\n",
      "Epoch 19/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9123 - accuracy: 0.6284 - val_loss: 0.8851 - val_accuracy: 0.6310\n",
      "Epoch 20/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8775 - accuracy: 0.6318 - val_loss: 0.8517 - val_accuracy: 0.6661\n",
      "Epoch 21/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8469 - accuracy: 0.6463 - val_loss: 0.8633 - val_accuracy: 0.6510\n",
      "Epoch 22/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8518 - accuracy: 0.6414 - val_loss: 0.8930 - val_accuracy: 0.6506\n",
      "Epoch 23/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8394 - accuracy: 0.6481 - val_loss: 0.8638 - val_accuracy: 0.6355\n",
      "Epoch 24/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8423 - accuracy: 0.6458 - val_loss: 0.8455 - val_accuracy: 0.6479\n",
      "Epoch 25/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8381 - accuracy: 0.6482 - val_loss: 0.9215 - val_accuracy: 0.6355\n",
      "Epoch 26/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8311 - accuracy: 0.6526 - val_loss: 0.8511 - val_accuracy: 0.6488\n",
      "Epoch 27/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8253 - accuracy: 0.6515 - val_loss: 0.8290 - val_accuracy: 0.6661\n",
      "Epoch 28/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8373 - accuracy: 0.6527 - val_loss: 0.8016 - val_accuracy: 0.6639\n",
      "Epoch 29/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8246 - accuracy: 0.6529 - val_loss: 0.8725 - val_accuracy: 0.6328\n",
      "Epoch 30/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8178 - accuracy: 0.6519 - val_loss: 0.8403 - val_accuracy: 0.6625\n",
      "Epoch 31/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8225 - accuracy: 0.6497 - val_loss: 0.8851 - val_accuracy: 0.6439\n",
      "Epoch 32/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8055 - accuracy: 0.6593 - val_loss: 0.8450 - val_accuracy: 0.6506\n",
      "Epoch 33/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7978 - accuracy: 0.6613 - val_loss: 0.8710 - val_accuracy: 0.6581\n",
      "Epoch 34/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8132 - accuracy: 0.6551 - val_loss: 0.8503 - val_accuracy: 0.6430\n",
      "Epoch 35/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8142 - accuracy: 0.6551 - val_loss: 0.8031 - val_accuracy: 0.6670\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7983 - accuracy: 0.6601 - val_loss: 0.8323 - val_accuracy: 0.6559\n",
      "Epoch 37/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7928 - accuracy: 0.6645 - val_loss: 0.8173 - val_accuracy: 0.6537\n",
      "Epoch 38/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7960 - accuracy: 0.6601 - val_loss: 0.8749 - val_accuracy: 0.6350\n",
      "Epoch 39/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7963 - accuracy: 0.6601 - val_loss: 0.8238 - val_accuracy: 0.6448\n",
      "Epoch 40/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7885 - accuracy: 0.6641 - val_loss: 0.7996 - val_accuracy: 0.6678\n",
      "Epoch 41/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8030 - accuracy: 0.6587 - val_loss: 0.7974 - val_accuracy: 0.6590\n",
      "Epoch 42/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7791 - accuracy: 0.6666 - val_loss: 0.8592 - val_accuracy: 0.6408\n",
      "Epoch 43/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7811 - accuracy: 0.6662 - val_loss: 0.8033 - val_accuracy: 0.6568\n",
      "Epoch 44/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7969 - accuracy: 0.6625 - val_loss: 0.8341 - val_accuracy: 0.6550\n",
      "Epoch 45/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7728 - accuracy: 0.6695 - val_loss: 0.7859 - val_accuracy: 0.6661\n",
      "Epoch 46/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7819 - accuracy: 0.6647 - val_loss: 0.7899 - val_accuracy: 0.6736\n",
      "Epoch 47/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7701 - accuracy: 0.6739 - val_loss: 0.7978 - val_accuracy: 0.6572\n",
      "Epoch 48/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7740 - accuracy: 0.6680 - val_loss: 0.7890 - val_accuracy: 0.6665\n",
      "Epoch 49/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7688 - accuracy: 0.6707 - val_loss: 0.7909 - val_accuracy: 0.6705\n",
      "Epoch 50/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7726 - accuracy: 0.6717 - val_loss: 0.7993 - val_accuracy: 0.6634\n",
      "Entrainement du numéro 7/11\n",
      "Epoch 1/50\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 3.5111 - accuracy: 0.5126 - val_loss: 1.2541 - val_accuracy: 0.5716\n",
      "Epoch 2/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.1232 - accuracy: 0.5706 - val_loss: 1.0823 - val_accuracy: 0.5769\n",
      "Epoch 3/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.0688 - accuracy: 0.5844 - val_loss: 0.9390 - val_accuracy: 0.6248\n",
      "Epoch 4/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.0229 - accuracy: 0.5910 - val_loss: 1.0582 - val_accuracy: 0.5570\n",
      "Epoch 5/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.0044 - accuracy: 0.6060 - val_loss: 0.9895 - val_accuracy: 0.5956\n",
      "Epoch 6/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9759 - accuracy: 0.6019 - val_loss: 0.9040 - val_accuracy: 0.6204\n",
      "Epoch 7/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9445 - accuracy: 0.6122 - val_loss: 1.0244 - val_accuracy: 0.6186\n",
      "Epoch 8/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9271 - accuracy: 0.6238 - val_loss: 0.9569 - val_accuracy: 0.6164\n",
      "Epoch 9/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9381 - accuracy: 0.6136 - val_loss: 0.8894 - val_accuracy: 0.6200\n",
      "Epoch 10/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9353 - accuracy: 0.6132 - val_loss: 0.9108 - val_accuracy: 0.6106\n",
      "Epoch 11/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8836 - accuracy: 0.6284 - val_loss: 0.8578 - val_accuracy: 0.6302\n",
      "Epoch 12/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8832 - accuracy: 0.6308 - val_loss: 0.9069 - val_accuracy: 0.6208\n",
      "Epoch 13/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8832 - accuracy: 0.6289 - val_loss: 0.8338 - val_accuracy: 0.6616\n",
      "Epoch 14/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8699 - accuracy: 0.6344 - val_loss: 0.8338 - val_accuracy: 0.6408\n",
      "Epoch 15/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8894 - accuracy: 0.6303 - val_loss: 0.9202 - val_accuracy: 0.6244\n",
      "Epoch 16/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8653 - accuracy: 0.6315 - val_loss: 0.8551 - val_accuracy: 0.6359\n",
      "Epoch 17/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.8462 - accuracy: 0.6429 - val_loss: 0.8420 - val_accuracy: 0.6545\n",
      "Epoch 18/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.8558 - accuracy: 0.6366 - val_loss: 0.8576 - val_accuracy: 0.6408\n",
      "Epoch 19/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8484 - accuracy: 0.6404 - val_loss: 0.8938 - val_accuracy: 0.6080\n",
      "Epoch 20/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8435 - accuracy: 0.6425 - val_loss: 0.9287 - val_accuracy: 0.6027\n",
      "Epoch 21/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8485 - accuracy: 0.6415 - val_loss: 0.8002 - val_accuracy: 0.6594\n",
      "Epoch 22/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8386 - accuracy: 0.6440 - val_loss: 0.8429 - val_accuracy: 0.6399\n",
      "Epoch 23/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8278 - accuracy: 0.6456 - val_loss: 0.8447 - val_accuracy: 0.6457\n",
      "Epoch 24/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8264 - accuracy: 0.6502 - val_loss: 0.8372 - val_accuracy: 0.6381\n",
      "Epoch 25/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8189 - accuracy: 0.6485 - val_loss: 0.8116 - val_accuracy: 0.6483\n",
      "Epoch 26/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8025 - accuracy: 0.6589 - val_loss: 0.8194 - val_accuracy: 0.6576\n",
      "Epoch 27/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8047 - accuracy: 0.6518 - val_loss: 0.8057 - val_accuracy: 0.6417\n",
      "Epoch 28/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8201 - accuracy: 0.6521 - val_loss: 0.8035 - val_accuracy: 0.6541\n",
      "Epoch 29/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8043 - accuracy: 0.6565 - val_loss: 0.7784 - val_accuracy: 0.6758\n",
      "Epoch 30/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8156 - accuracy: 0.6570 - val_loss: 0.8668 - val_accuracy: 0.6430\n",
      "Epoch 31/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7968 - accuracy: 0.6639 - val_loss: 0.7761 - val_accuracy: 0.6714\n",
      "Epoch 32/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8035 - accuracy: 0.6587 - val_loss: 0.8281 - val_accuracy: 0.6532\n",
      "Epoch 33/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8099 - accuracy: 0.6558 - val_loss: 0.7812 - val_accuracy: 0.6696\n",
      "Epoch 34/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8013 - accuracy: 0.6575 - val_loss: 0.7999 - val_accuracy: 0.6550\n",
      "Epoch 35/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7947 - accuracy: 0.6600 - val_loss: 0.8411 - val_accuracy: 0.6532\n",
      "Epoch 36/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.7989 - accuracy: 0.6613 - val_loss: 0.7888 - val_accuracy: 0.6639\n",
      "Epoch 37/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.7808 - accuracy: 0.6669 - val_loss: 0.8022 - val_accuracy: 0.6603\n",
      "Epoch 38/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7902 - accuracy: 0.6627 - val_loss: 0.7845 - val_accuracy: 0.6678\n",
      "Epoch 39/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7817 - accuracy: 0.6674 - val_loss: 0.7901 - val_accuracy: 0.6576\n",
      "Epoch 40/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7779 - accuracy: 0.6704 - val_loss: 0.7737 - val_accuracy: 0.6718\n",
      "Epoch 41/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7696 - accuracy: 0.6711 - val_loss: 0.7620 - val_accuracy: 0.6843\n",
      "Epoch 42/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7616 - accuracy: 0.6739 - val_loss: 0.7854 - val_accuracy: 0.6608\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7757 - accuracy: 0.6696 - val_loss: 0.8115 - val_accuracy: 0.6506\n",
      "Epoch 44/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7840 - accuracy: 0.6676 - val_loss: 0.7719 - val_accuracy: 0.6705\n",
      "Epoch 45/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7721 - accuracy: 0.6725 - val_loss: 0.7909 - val_accuracy: 0.6674\n",
      "Epoch 46/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7755 - accuracy: 0.6699 - val_loss: 0.7544 - val_accuracy: 0.6763\n",
      "Epoch 47/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7646 - accuracy: 0.6716 - val_loss: 0.7546 - val_accuracy: 0.6851\n",
      "Epoch 48/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7513 - accuracy: 0.6825 - val_loss: 0.7424 - val_accuracy: 0.6851\n",
      "Epoch 49/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7446 - accuracy: 0.6787 - val_loss: 0.7542 - val_accuracy: 0.6714\n",
      "Epoch 50/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7472 - accuracy: 0.6818 - val_loss: 0.7541 - val_accuracy: 0.6732\n",
      "Entrainement du numéro 8/11\n",
      "Epoch 1/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 4.2508 - accuracy: 0.4941 - val_loss: 1.4035 - val_accuracy: 0.5113\n",
      "Epoch 2/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.3702 - accuracy: 0.5473 - val_loss: 1.5926 - val_accuracy: 0.5503\n",
      "Epoch 3/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.1718 - accuracy: 0.5757 - val_loss: 1.2004 - val_accuracy: 0.5694\n",
      "Epoch 4/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 1.1225 - accuracy: 0.5753 - val_loss: 1.0358 - val_accuracy: 0.5956\n",
      "Epoch 5/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.0479 - accuracy: 0.5917 - val_loss: 1.0348 - val_accuracy: 0.6089\n",
      "Epoch 6/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.0335 - accuracy: 0.5924 - val_loss: 1.0266 - val_accuracy: 0.5973\n",
      "Epoch 7/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.0323 - accuracy: 0.5885 - val_loss: 0.9691 - val_accuracy: 0.6080\n",
      "Epoch 8/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.0037 - accuracy: 0.5941 - val_loss: 0.9304 - val_accuracy: 0.6346\n",
      "Epoch 9/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9548 - accuracy: 0.6134 - val_loss: 0.9515 - val_accuracy: 0.6120\n",
      "Epoch 10/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9456 - accuracy: 0.6117 - val_loss: 0.8833 - val_accuracy: 0.6470\n",
      "Epoch 11/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9458 - accuracy: 0.6120 - val_loss: 0.9020 - val_accuracy: 0.6390\n",
      "Epoch 12/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9016 - accuracy: 0.6237 - val_loss: 0.9016 - val_accuracy: 0.6098\n",
      "Epoch 13/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9383 - accuracy: 0.6063 - val_loss: 0.8939 - val_accuracy: 0.6341\n",
      "Epoch 14/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9449 - accuracy: 0.6075 - val_loss: 0.9060 - val_accuracy: 0.6155\n",
      "Epoch 15/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9067 - accuracy: 0.6252 - val_loss: 0.8711 - val_accuracy: 0.6404\n",
      "Epoch 16/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9021 - accuracy: 0.6203 - val_loss: 0.8528 - val_accuracy: 0.6204\n",
      "Epoch 17/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8712 - accuracy: 0.6296 - val_loss: 0.9199 - val_accuracy: 0.6013\n",
      "Epoch 18/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8765 - accuracy: 0.6275 - val_loss: 0.8499 - val_accuracy: 0.6368\n",
      "Epoch 19/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.8654 - accuracy: 0.6298 - val_loss: 0.8279 - val_accuracy: 0.6466\n",
      "Epoch 20/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8631 - accuracy: 0.6281 - val_loss: 0.9175 - val_accuracy: 0.6102\n",
      "Epoch 21/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8635 - accuracy: 0.6327 - val_loss: 0.8308 - val_accuracy: 0.6359\n",
      "Epoch 22/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8355 - accuracy: 0.6369 - val_loss: 0.8408 - val_accuracy: 0.6421\n",
      "Epoch 23/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8211 - accuracy: 0.6476 - val_loss: 0.7884 - val_accuracy: 0.6590\n",
      "Epoch 24/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8219 - accuracy: 0.6485 - val_loss: 0.8196 - val_accuracy: 0.6364\n",
      "Epoch 25/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8092 - accuracy: 0.6521 - val_loss: 0.8004 - val_accuracy: 0.6656\n",
      "Epoch 26/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8208 - accuracy: 0.6500 - val_loss: 0.7756 - val_accuracy: 0.6616\n",
      "Epoch 27/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7810 - accuracy: 0.6581 - val_loss: 0.8008 - val_accuracy: 0.6736\n",
      "Epoch 28/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8098 - accuracy: 0.6521 - val_loss: 0.7993 - val_accuracy: 0.6634\n",
      "Epoch 29/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7889 - accuracy: 0.6586 - val_loss: 0.7721 - val_accuracy: 0.6803\n",
      "Epoch 30/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8111 - accuracy: 0.6517 - val_loss: 0.8599 - val_accuracy: 0.6461\n",
      "Epoch 31/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8025 - accuracy: 0.6507 - val_loss: 0.7806 - val_accuracy: 0.6727\n",
      "Epoch 32/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7657 - accuracy: 0.6653 - val_loss: 0.7751 - val_accuracy: 0.6643\n",
      "Epoch 33/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7624 - accuracy: 0.6707 - val_loss: 0.7757 - val_accuracy: 0.6590\n",
      "Epoch 34/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7594 - accuracy: 0.6699 - val_loss: 0.8102 - val_accuracy: 0.6647\n",
      "Epoch 35/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7619 - accuracy: 0.6680 - val_loss: 0.7382 - val_accuracy: 0.6825\n",
      "Epoch 36/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7561 - accuracy: 0.6691 - val_loss: 0.7957 - val_accuracy: 0.6621\n",
      "Epoch 37/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7607 - accuracy: 0.6682 - val_loss: 0.7462 - val_accuracy: 0.6847\n",
      "Epoch 38/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7407 - accuracy: 0.6747 - val_loss: 0.7472 - val_accuracy: 0.6758\n",
      "Epoch 39/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7362 - accuracy: 0.6841 - val_loss: 0.7462 - val_accuracy: 0.6772\n",
      "Epoch 40/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7341 - accuracy: 0.6827 - val_loss: 0.7536 - val_accuracy: 0.6780\n",
      "Epoch 41/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7433 - accuracy: 0.6777 - val_loss: 0.7522 - val_accuracy: 0.6914\n",
      "Epoch 42/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7355 - accuracy: 0.6793 - val_loss: 0.7494 - val_accuracy: 0.6718\n",
      "Epoch 43/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.7330 - accuracy: 0.6780 - val_loss: 0.7293 - val_accuracy: 0.6896\n",
      "Epoch 44/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.7165 - accuracy: 0.6898 - val_loss: 0.7267 - val_accuracy: 0.6838\n",
      "Epoch 45/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7200 - accuracy: 0.6875 - val_loss: 0.7404 - val_accuracy: 0.6772\n",
      "Epoch 46/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7183 - accuracy: 0.6883 - val_loss: 0.7450 - val_accuracy: 0.6882\n",
      "Epoch 47/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7208 - accuracy: 0.6836 - val_loss: 0.7295 - val_accuracy: 0.6878\n",
      "Epoch 48/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7093 - accuracy: 0.6897 - val_loss: 0.7559 - val_accuracy: 0.6705\n",
      "Epoch 49/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7160 - accuracy: 0.6907 - val_loss: 0.7116 - val_accuracy: 0.6958\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7060 - accuracy: 0.6946 - val_loss: 0.7094 - val_accuracy: 0.6993\n",
      "Entrainement du numéro 9/11\n",
      "Epoch 1/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 3.4003 - accuracy: 0.4974 - val_loss: 1.3122 - val_accuracy: 0.5384\n",
      "Epoch 2/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.1056 - accuracy: 0.5647 - val_loss: 1.0928 - val_accuracy: 0.5672\n",
      "Epoch 3/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.0259 - accuracy: 0.5810 - val_loss: 0.9531 - val_accuracy: 0.5858\n",
      "Epoch 4/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.0173 - accuracy: 0.5826 - val_loss: 0.9879 - val_accuracy: 0.5933\n",
      "Epoch 5/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9640 - accuracy: 0.5963 - val_loss: 0.9969 - val_accuracy: 0.5761\n",
      "Epoch 6/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9416 - accuracy: 0.6024 - val_loss: 0.9319 - val_accuracy: 0.6058\n",
      "Epoch 7/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9344 - accuracy: 0.6068 - val_loss: 1.0714 - val_accuracy: 0.5583\n",
      "Epoch 8/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.8993 - accuracy: 0.6213 - val_loss: 0.9556 - val_accuracy: 0.6062\n",
      "Epoch 9/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.9276 - accuracy: 0.6095 - val_loss: 0.9286 - val_accuracy: 0.6124\n",
      "Epoch 10/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8995 - accuracy: 0.6175 - val_loss: 0.9107 - val_accuracy: 0.6222\n",
      "Epoch 11/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8765 - accuracy: 0.6234 - val_loss: 0.8870 - val_accuracy: 0.6244\n",
      "Epoch 12/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8681 - accuracy: 0.6296 - val_loss: 0.8548 - val_accuracy: 0.6355\n",
      "Epoch 13/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8766 - accuracy: 0.6252 - val_loss: 0.8604 - val_accuracy: 0.6271\n",
      "Epoch 14/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8446 - accuracy: 0.6384 - val_loss: 0.9388 - val_accuracy: 0.5920\n",
      "Epoch 15/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8654 - accuracy: 0.6255 - val_loss: 0.8900 - val_accuracy: 0.6160\n",
      "Epoch 16/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8513 - accuracy: 0.6364 - val_loss: 0.8670 - val_accuracy: 0.6129\n",
      "Epoch 17/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8672 - accuracy: 0.6306 - val_loss: 0.8780 - val_accuracy: 0.6111\n",
      "Epoch 18/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8319 - accuracy: 0.6421 - val_loss: 0.8450 - val_accuracy: 0.6448\n",
      "Epoch 19/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8418 - accuracy: 0.6413 - val_loss: 0.8287 - val_accuracy: 0.6510\n",
      "Epoch 20/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8228 - accuracy: 0.6496 - val_loss: 0.8311 - val_accuracy: 0.6439\n",
      "Epoch 21/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8290 - accuracy: 0.6452 - val_loss: 0.8464 - val_accuracy: 0.6341\n",
      "Epoch 22/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8119 - accuracy: 0.6543 - val_loss: 0.8739 - val_accuracy: 0.6310\n",
      "Epoch 23/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8160 - accuracy: 0.6528 - val_loss: 0.9302 - val_accuracy: 0.6204\n",
      "Epoch 24/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8116 - accuracy: 0.6557 - val_loss: 0.8306 - val_accuracy: 0.6510\n",
      "Epoch 25/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8059 - accuracy: 0.6583 - val_loss: 0.8449 - val_accuracy: 0.6337\n",
      "Epoch 26/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8169 - accuracy: 0.6524 - val_loss: 0.8345 - val_accuracy: 0.6581\n",
      "Epoch 27/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8050 - accuracy: 0.6583 - val_loss: 0.8837 - val_accuracy: 0.5991\n",
      "Epoch 28/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7912 - accuracy: 0.6658 - val_loss: 0.8723 - val_accuracy: 0.6466\n",
      "Epoch 29/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7943 - accuracy: 0.6635 - val_loss: 0.8494 - val_accuracy: 0.6248\n",
      "Epoch 30/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7906 - accuracy: 0.6662 - val_loss: 0.8542 - val_accuracy: 0.6253\n",
      "Epoch 31/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7971 - accuracy: 0.6653 - val_loss: 0.8186 - val_accuracy: 0.6435\n",
      "Epoch 32/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7795 - accuracy: 0.6685 - val_loss: 0.9308 - val_accuracy: 0.5871\n",
      "Epoch 33/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7895 - accuracy: 0.6632 - val_loss: 0.8471 - val_accuracy: 0.6550\n",
      "Epoch 34/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7745 - accuracy: 0.6740 - val_loss: 0.8079 - val_accuracy: 0.6665\n",
      "Epoch 35/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7693 - accuracy: 0.6736 - val_loss: 0.7870 - val_accuracy: 0.6647\n",
      "Epoch 36/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7496 - accuracy: 0.6823 - val_loss: 0.7792 - val_accuracy: 0.6763\n",
      "Epoch 37/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7534 - accuracy: 0.6816 - val_loss: 0.8356 - val_accuracy: 0.6377\n",
      "Epoch 38/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7467 - accuracy: 0.6852 - val_loss: 0.7860 - val_accuracy: 0.6745\n",
      "Epoch 39/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7424 - accuracy: 0.6845 - val_loss: 0.8490 - val_accuracy: 0.6368\n",
      "Epoch 40/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7397 - accuracy: 0.6851 - val_loss: 0.7792 - val_accuracy: 0.6581\n",
      "Epoch 41/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7414 - accuracy: 0.6839 - val_loss: 0.7596 - val_accuracy: 0.6807\n",
      "Epoch 42/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.7250 - accuracy: 0.6873 - val_loss: 0.7616 - val_accuracy: 0.6727\n",
      "Epoch 43/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.7216 - accuracy: 0.6900 - val_loss: 0.7434 - val_accuracy: 0.6851\n",
      "Epoch 44/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7174 - accuracy: 0.6956 - val_loss: 0.7366 - val_accuracy: 0.6856\n",
      "Epoch 45/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7234 - accuracy: 0.6914 - val_loss: 0.7850 - val_accuracy: 0.6506\n",
      "Epoch 46/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7179 - accuracy: 0.6924 - val_loss: 0.7347 - val_accuracy: 0.6758\n",
      "Epoch 47/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7180 - accuracy: 0.6922 - val_loss: 0.7508 - val_accuracy: 0.6794\n",
      "Epoch 48/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7083 - accuracy: 0.6994 - val_loss: 0.7502 - val_accuracy: 0.6798\n",
      "Epoch 49/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7142 - accuracy: 0.6955 - val_loss: 0.7170 - val_accuracy: 0.6940\n",
      "Epoch 50/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.6976 - accuracy: 0.6994 - val_loss: 0.7752 - val_accuracy: 0.6506\n",
      "Entrainement du numéro 10/11\n",
      "Epoch 1/50\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 2.4684 - accuracy: 0.5135 - val_loss: 1.3068 - val_accuracy: 0.5180\n",
      "Epoch 2/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.1338 - accuracy: 0.5668 - val_loss: 1.0596 - val_accuracy: 0.5827\n",
      "Epoch 3/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.0175 - accuracy: 0.5789 - val_loss: 1.0016 - val_accuracy: 0.5787\n",
      "Epoch 4/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9667 - accuracy: 0.5983 - val_loss: 1.0705 - val_accuracy: 0.6062\n",
      "Epoch 5/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.9474 - accuracy: 0.6030 - val_loss: 0.9386 - val_accuracy: 0.6080\n",
      "Epoch 6/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9329 - accuracy: 0.6091 - val_loss: 1.0220 - val_accuracy: 0.5956\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 0s 3ms/step - loss: 0.9270 - accuracy: 0.6068 - val_loss: 1.0018 - val_accuracy: 0.6053\n",
      "Epoch 8/50\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.8913 - accuracy: 0.6232 - val_loss: 0.8859 - val_accuracy: 0.6124\n",
      "Epoch 9/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8704 - accuracy: 0.6270 - val_loss: 0.8843 - val_accuracy: 0.6217\n",
      "Epoch 10/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8720 - accuracy: 0.6289 - val_loss: 0.9096 - val_accuracy: 0.6160\n",
      "Epoch 11/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8813 - accuracy: 0.6245 - val_loss: 0.9069 - val_accuracy: 0.6151\n",
      "Epoch 12/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8703 - accuracy: 0.6306 - val_loss: 0.9046 - val_accuracy: 0.6102\n",
      "Epoch 13/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8734 - accuracy: 0.6199 - val_loss: 0.8921 - val_accuracy: 0.6195\n",
      "Epoch 14/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8563 - accuracy: 0.6312 - val_loss: 0.8708 - val_accuracy: 0.6200\n",
      "Epoch 15/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8442 - accuracy: 0.6332 - val_loss: 0.9036 - val_accuracy: 0.6155\n",
      "Epoch 16/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8427 - accuracy: 0.6390 - val_loss: 1.0025 - val_accuracy: 0.5450\n",
      "Epoch 17/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8368 - accuracy: 0.6408 - val_loss: 0.9967 - val_accuracy: 0.6013\n",
      "Epoch 18/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8425 - accuracy: 0.6405 - val_loss: 0.8464 - val_accuracy: 0.6341\n",
      "Epoch 19/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8395 - accuracy: 0.6382 - val_loss: 1.0136 - val_accuracy: 0.6501\n",
      "Epoch 20/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8241 - accuracy: 0.6469 - val_loss: 0.9015 - val_accuracy: 0.6466\n",
      "Epoch 21/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8112 - accuracy: 0.6541 - val_loss: 0.8701 - val_accuracy: 0.6373\n",
      "Epoch 22/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8105 - accuracy: 0.6535 - val_loss: 0.8413 - val_accuracy: 0.6350\n",
      "Epoch 23/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7983 - accuracy: 0.6555 - val_loss: 0.8727 - val_accuracy: 0.6412\n",
      "Epoch 24/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8023 - accuracy: 0.6581 - val_loss: 0.8436 - val_accuracy: 0.6559\n",
      "Epoch 25/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8059 - accuracy: 0.6521 - val_loss: 0.8393 - val_accuracy: 0.6315\n",
      "Epoch 26/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8060 - accuracy: 0.6521 - val_loss: 0.8057 - val_accuracy: 0.6550\n",
      "Epoch 27/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8096 - accuracy: 0.6512 - val_loss: 0.8684 - val_accuracy: 0.6377\n",
      "Epoch 28/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7956 - accuracy: 0.6563 - val_loss: 0.8322 - val_accuracy: 0.6430\n",
      "Epoch 29/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.7952 - accuracy: 0.6589 - val_loss: 0.8190 - val_accuracy: 0.6390\n",
      "Epoch 30/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7946 - accuracy: 0.6579 - val_loss: 0.8226 - val_accuracy: 0.6630\n",
      "Epoch 31/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7896 - accuracy: 0.6620 - val_loss: 0.8702 - val_accuracy: 0.6222\n",
      "Epoch 32/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7826 - accuracy: 0.6643 - val_loss: 0.9655 - val_accuracy: 0.6674\n",
      "Epoch 33/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7869 - accuracy: 0.6617 - val_loss: 0.7949 - val_accuracy: 0.6501\n",
      "Epoch 34/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7800 - accuracy: 0.6662 - val_loss: 0.8031 - val_accuracy: 0.6501\n",
      "Epoch 35/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7742 - accuracy: 0.6671 - val_loss: 0.8809 - val_accuracy: 0.6399\n",
      "Epoch 36/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.7661 - accuracy: 0.6696 - val_loss: 0.7922 - val_accuracy: 0.6736\n",
      "Epoch 37/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7719 - accuracy: 0.6702 - val_loss: 0.8185 - val_accuracy: 0.6643\n",
      "Epoch 38/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7607 - accuracy: 0.6724 - val_loss: 0.7803 - val_accuracy: 0.6741\n",
      "Epoch 39/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7416 - accuracy: 0.6831 - val_loss: 0.8167 - val_accuracy: 0.6297\n",
      "Epoch 40/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7430 - accuracy: 0.6817 - val_loss: 0.9075 - val_accuracy: 0.6457\n",
      "Epoch 41/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7386 - accuracy: 0.6793 - val_loss: 0.7785 - val_accuracy: 0.6639\n",
      "Epoch 42/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.7306 - accuracy: 0.6849 - val_loss: 0.8103 - val_accuracy: 0.6656\n",
      "Epoch 43/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7257 - accuracy: 0.6892 - val_loss: 0.7501 - val_accuracy: 0.6785\n",
      "Epoch 44/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7215 - accuracy: 0.6899 - val_loss: 0.8188 - val_accuracy: 0.6452\n",
      "Epoch 45/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7161 - accuracy: 0.6910 - val_loss: 0.7619 - val_accuracy: 0.6878\n",
      "Epoch 46/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7144 - accuracy: 0.6922 - val_loss: 0.8251 - val_accuracy: 0.6741\n",
      "Epoch 47/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.7202 - accuracy: 0.6865 - val_loss: 0.7768 - val_accuracy: 0.6643\n",
      "Epoch 48/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7076 - accuracy: 0.6927 - val_loss: 0.7393 - val_accuracy: 0.6869\n",
      "Epoch 49/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7036 - accuracy: 0.6978 - val_loss: 0.8321 - val_accuracy: 0.6563\n",
      "Epoch 50/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7031 - accuracy: 0.6967 - val_loss: 0.7654 - val_accuracy: 0.6847\n",
      "Entrainement du numéro 11/11\n",
      "Epoch 1/50\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 3.2400 - accuracy: 0.5018 - val_loss: 1.3825 - val_accuracy: 0.5769\n",
      "Epoch 2/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.2795 - accuracy: 0.5465 - val_loss: 1.2411 - val_accuracy: 0.5255\n",
      "Epoch 3/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 1.1178 - accuracy: 0.5690 - val_loss: 1.1156 - val_accuracy: 0.5765\n",
      "Epoch 4/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.0332 - accuracy: 0.5904 - val_loss: 1.1651 - val_accuracy: 0.5246\n",
      "Epoch 5/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.0553 - accuracy: 0.5808 - val_loss: 1.1610 - val_accuracy: 0.5645\n",
      "Epoch 6/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 1.0220 - accuracy: 0.5921 - val_loss: 1.1870 - val_accuracy: 0.5237\n",
      "Epoch 7/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9940 - accuracy: 0.5956 - val_loss: 0.9501 - val_accuracy: 0.6195\n",
      "Epoch 8/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9467 - accuracy: 0.6060 - val_loss: 1.0712 - val_accuracy: 0.5885\n",
      "Epoch 9/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9192 - accuracy: 0.6195 - val_loss: 0.9529 - val_accuracy: 0.6160\n",
      "Epoch 10/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9277 - accuracy: 0.6184 - val_loss: 0.9074 - val_accuracy: 0.6333\n",
      "Epoch 11/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9116 - accuracy: 0.6224 - val_loss: 0.8640 - val_accuracy: 0.6443\n",
      "Epoch 12/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.9001 - accuracy: 0.6233 - val_loss: 0.8636 - val_accuracy: 0.6412\n",
      "Epoch 13/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.9188 - accuracy: 0.6126 - val_loss: 0.8782 - val_accuracy: 0.6479\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 3ms/step - loss: 0.9026 - accuracy: 0.6225 - val_loss: 0.9068 - val_accuracy: 0.6275\n",
      "Epoch 15/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8805 - accuracy: 0.6314 - val_loss: 0.8676 - val_accuracy: 0.6350\n",
      "Epoch 16/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8821 - accuracy: 0.6221 - val_loss: 0.8440 - val_accuracy: 0.6497\n",
      "Epoch 17/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8538 - accuracy: 0.6361 - val_loss: 0.8386 - val_accuracy: 0.6608\n",
      "Epoch 18/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8387 - accuracy: 0.6443 - val_loss: 1.0186 - val_accuracy: 0.5894\n",
      "Epoch 19/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8530 - accuracy: 0.6364 - val_loss: 0.9059 - val_accuracy: 0.6239\n",
      "Epoch 20/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8505 - accuracy: 0.6380 - val_loss: 0.8785 - val_accuracy: 0.6466\n",
      "Epoch 21/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8589 - accuracy: 0.6367 - val_loss: 0.8781 - val_accuracy: 0.6461\n",
      "Epoch 22/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8233 - accuracy: 0.6503 - val_loss: 0.8343 - val_accuracy: 0.6501\n",
      "Epoch 23/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8500 - accuracy: 0.6373 - val_loss: 0.8710 - val_accuracy: 0.6612\n",
      "Epoch 24/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8257 - accuracy: 0.6458 - val_loss: 0.8742 - val_accuracy: 0.6306\n",
      "Epoch 25/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8643 - accuracy: 0.6329 - val_loss: 0.9088 - val_accuracy: 0.6271\n",
      "Epoch 26/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8186 - accuracy: 0.6461 - val_loss: 0.8279 - val_accuracy: 0.6608\n",
      "Epoch 27/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8325 - accuracy: 0.6426 - val_loss: 0.8703 - val_accuracy: 0.6443\n",
      "Epoch 28/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8313 - accuracy: 0.6416 - val_loss: 0.8557 - val_accuracy: 0.6355\n",
      "Epoch 29/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8197 - accuracy: 0.6530 - val_loss: 0.8518 - val_accuracy: 0.6461\n",
      "Epoch 30/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7927 - accuracy: 0.6641 - val_loss: 0.8704 - val_accuracy: 0.6390\n",
      "Epoch 31/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8174 - accuracy: 0.6508 - val_loss: 0.8449 - val_accuracy: 0.6506\n",
      "Epoch 32/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8154 - accuracy: 0.6500 - val_loss: 0.8078 - val_accuracy: 0.6616\n",
      "Epoch 33/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7953 - accuracy: 0.6599 - val_loss: 0.8235 - val_accuracy: 0.6678\n",
      "Epoch 34/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.8106 - accuracy: 0.6535 - val_loss: 0.8480 - val_accuracy: 0.6590\n",
      "Epoch 35/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7974 - accuracy: 0.6602 - val_loss: 0.8368 - val_accuracy: 0.6537\n",
      "Epoch 36/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7955 - accuracy: 0.6584 - val_loss: 0.8547 - val_accuracy: 0.6687\n",
      "Epoch 37/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7920 - accuracy: 0.6614 - val_loss: 0.8231 - val_accuracy: 0.6537\n",
      "Epoch 38/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7983 - accuracy: 0.6601 - val_loss: 0.8531 - val_accuracy: 0.6430\n",
      "Epoch 39/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7830 - accuracy: 0.6638 - val_loss: 0.8185 - val_accuracy: 0.6612\n",
      "Epoch 40/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7828 - accuracy: 0.6645 - val_loss: 0.8154 - val_accuracy: 0.6674\n",
      "Epoch 41/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7813 - accuracy: 0.6644 - val_loss: 0.8860 - val_accuracy: 0.6310\n",
      "Epoch 42/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7773 - accuracy: 0.6714 - val_loss: 0.8223 - val_accuracy: 0.6590\n",
      "Epoch 43/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7872 - accuracy: 0.6635 - val_loss: 0.8050 - val_accuracy: 0.6692\n",
      "Epoch 44/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.7882 - accuracy: 0.6630 - val_loss: 0.8137 - val_accuracy: 0.6568\n",
      "Epoch 45/50\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.7720 - accuracy: 0.6687 - val_loss: 0.7843 - val_accuracy: 0.6780\n",
      "Epoch 46/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7692 - accuracy: 0.6725 - val_loss: 0.8964 - val_accuracy: 0.5925\n",
      "Epoch 47/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7716 - accuracy: 0.6648 - val_loss: 0.8121 - val_accuracy: 0.6630\n",
      "Epoch 48/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7528 - accuracy: 0.6744 - val_loss: 0.7740 - val_accuracy: 0.6798\n",
      "Epoch 49/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7624 - accuracy: 0.6673 - val_loss: 0.8110 - val_accuracy: 0.6608\n",
      "Epoch 50/50\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.7523 - accuracy: 0.6759 - val_loss: 0.7815 - val_accuracy: 0.6834\n"
     ]
    }
   ],
   "source": [
    "global_model.fit(X_train, y_train, validation_split=0.1, batch_size=128, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "pMIimVdVzOEb"
   },
   "outputs": [],
   "source": [
    "preds = global_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q049Y7srxlqz",
    "outputId": "a90723ff-fba6-448f-c3f4-870be9564296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7028644237282669\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnDbASDAYNeA"
   },
   "source": [
    "### 3. LSTM model with data separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "llHzDoG02qIb"
   },
   "outputs": [],
   "source": [
    "class RecurrentNetwork:\n",
    "  def __init__(self, X1, X2):\n",
    "    input1 = keras.Input(shape=X1.shape[1], name=\"Input1\")\n",
    "    input2 = keras.Input(shape=X2.shape[1], name=\"Input2\")\n",
    "\n",
    "    output1 = keras.layers.Embedding(10, 10)(input1)\n",
    "    output1 = keras.layers.LSTM(32, return_sequences=True)(output1)\n",
    "    output1 = keras.layers.Flatten()(output1)\n",
    "\n",
    "    input2 = keras.Input(shape=X2.shape[1], name=\"Input2\")\n",
    "    concat_layer= keras.layers.Concatenate(name=\"Concat\")([output1, input2])\n",
    "\n",
    "    output2 = keras.layers.Dense(64, activation='relu', name=\"Dense4\")(concat_layer)\n",
    "    output2 = keras.layers.Dense(32, activation='relu', name=\"Dense5\")(concat_layer)\n",
    "    output2 = keras.layers.Dense(6, activation='softmax', name=\"Dense6\")(output2)\n",
    "\n",
    "    self.model = Model([input1, input2], output2)\n",
    "    self.model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "  def fit(self, X, y, validation_split=0, batch_size=128, epochs=5):\n",
    "    y = keras.utils.to_categorical(y, 6)\n",
    "    history = self.model.fit(X, y, validation_split=validation_split, batch_size=batch_size, epochs=epochs)\n",
    "    return history\n",
    "\n",
    "  def predict(self, X):\n",
    "    preds = self.model.predict(X)\n",
    "    res = []\n",
    "    n = len(preds)\n",
    "    for i in range(n):\n",
    "      res.append(np.argmax(preds[i]))\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "8U88E52e2hiz"
   },
   "outputs": [],
   "source": [
    "# We separate the \"change_status_date\" columns\n",
    "def separate_data(X):\n",
    "  return X.iloc[:, :5], X.iloc[:, 5:]\n",
    "\n",
    "X1, X2 = separate_data(X)\n",
    "X1_train, X2_train = separate_data(X_train)\n",
    "X1_test, X2_test = separate_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 797
    },
    "id": "b-q_Cq51dvkx",
    "outputId": "789bd9c8-1a85-4d75-ecbf-228b0a6dd769"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1090/1090 [==============================] - 18s 15ms/step - loss: 3.3363 - accuracy: 0.5760 - val_loss: 0.9139 - val_accuracy: 0.6451\n",
      "Epoch 2/50\n",
      "1090/1090 [==============================] - 18s 17ms/step - loss: 0.8343 - accuracy: 0.6541 - val_loss: 0.8620 - val_accuracy: 0.6420\n",
      "Epoch 3/50\n",
      "1090/1090 [==============================] - 19s 17ms/step - loss: 0.7628 - accuracy: 0.6759 - val_loss: 0.7500 - val_accuracy: 0.6990\n",
      "Epoch 4/50\n",
      "1090/1090 [==============================] - 14s 13ms/step - loss: 0.7450 - accuracy: 0.6840 - val_loss: 0.7288 - val_accuracy: 0.7018\n",
      "Epoch 5/50\n",
      "1090/1090 [==============================] - 16s 15ms/step - loss: 0.7325 - accuracy: 0.6870 - val_loss: 0.7338 - val_accuracy: 0.6941\n",
      "Epoch 6/50\n",
      "1090/1090 [==============================] - 17s 15ms/step - loss: 0.7267 - accuracy: 0.6897 - val_loss: 0.7169 - val_accuracy: 0.7016\n",
      "Epoch 7/50\n",
      "1090/1090 [==============================] - 15s 14ms/step - loss: 0.7263 - accuracy: 0.6879 - val_loss: 0.7257 - val_accuracy: 0.7021\n",
      "Epoch 8/50\n",
      "1090/1090 [==============================] - 14s 13ms/step - loss: 0.7233 - accuracy: 0.6904 - val_loss: 0.7049 - val_accuracy: 0.7059\n",
      "Epoch 9/50\n",
      "1090/1090 [==============================] - 18s 17ms/step - loss: 0.7160 - accuracy: 0.6916 - val_loss: 0.6964 - val_accuracy: 0.6990\n",
      "Epoch 10/50\n",
      "1090/1090 [==============================] - 15s 14ms/step - loss: 0.7137 - accuracy: 0.6922 - val_loss: 0.7346 - val_accuracy: 0.6716\n",
      "Epoch 11/50\n",
      "1090/1090 [==============================] - 17s 16ms/step - loss: 0.7141 - accuracy: 0.6903 - val_loss: 0.7088 - val_accuracy: 0.6864\n",
      "Epoch 12/50\n",
      "1090/1090 [==============================] - 15s 14ms/step - loss: 0.7111 - accuracy: 0.6922 - val_loss: 0.7119 - val_accuracy: 0.7019\n",
      "Epoch 13/50\n",
      "1090/1090 [==============================] - 18s 17ms/step - loss: 0.7109 - accuracy: 0.6926 - val_loss: 0.6928 - val_accuracy: 0.7076\n",
      "Epoch 14/50\n",
      "1090/1090 [==============================] - 17s 16ms/step - loss: 0.7092 - accuracy: 0.6921 - val_loss: 0.8524 - val_accuracy: 0.6487\n",
      "Epoch 15/50\n",
      "1090/1090 [==============================] - 16s 14ms/step - loss: 0.7099 - accuracy: 0.6927 - val_loss: 0.6917 - val_accuracy: 0.7094\n",
      "Epoch 16/50\n",
      "1090/1090 [==============================] - 18s 17ms/step - loss: 0.7101 - accuracy: 0.6930 - val_loss: 0.7075 - val_accuracy: 0.6876\n",
      "Epoch 17/50\n",
      "1090/1090 [==============================] - 17s 15ms/step - loss: 0.7058 - accuracy: 0.6937 - val_loss: 0.6893 - val_accuracy: 0.7047\n",
      "Epoch 18/50\n",
      "1090/1090 [==============================] - 15s 14ms/step - loss: 0.7024 - accuracy: 0.6964 - val_loss: 0.6934 - val_accuracy: 0.7068\n",
      "Epoch 19/50\n",
      "1090/1090 [==============================] - 17s 16ms/step - loss: 0.7006 - accuracy: 0.6961 - val_loss: 0.7685 - val_accuracy: 0.6605\n",
      "Epoch 20/50\n",
      "1090/1090 [==============================] - 17s 15ms/step - loss: 0.6995 - accuracy: 0.6973 - val_loss: 0.6800 - val_accuracy: 0.7107\n",
      "Epoch 21/50\n",
      "1090/1090 [==============================] - 17s 16ms/step - loss: 0.6900 - accuracy: 0.7018 - val_loss: 0.6820 - val_accuracy: 0.7089\n",
      "Epoch 22/50\n",
      "1090/1090 [==============================] - 15s 14ms/step - loss: 0.6874 - accuracy: 0.7029 - val_loss: 0.7257 - val_accuracy: 0.6872\n",
      "Epoch 23/50\n",
      "1090/1090 [==============================] - 14s 13ms/step - loss: 0.6871 - accuracy: 0.7028 - val_loss: 0.6801 - val_accuracy: 0.7110\n",
      "Epoch 24/50\n",
      "1090/1090 [==============================] - 16s 15ms/step - loss: 0.6860 - accuracy: 0.7022 - val_loss: 0.6746 - val_accuracy: 0.7140\n",
      "Epoch 25/50\n",
      "1090/1090 [==============================] - 17s 16ms/step - loss: 0.6844 - accuracy: 0.7041 - val_loss: 0.6970 - val_accuracy: 0.6978\n",
      "Epoch 26/50\n",
      "1090/1090 [==============================] - 17s 15ms/step - loss: 0.6813 - accuracy: 0.7053 - val_loss: 0.6773 - val_accuracy: 0.7132\n",
      "Epoch 27/50\n",
      "1090/1090 [==============================] - 16s 15ms/step - loss: 0.6803 - accuracy: 0.7056 - val_loss: 0.6714 - val_accuracy: 0.7118\n",
      "Epoch 28/50\n",
      "1090/1090 [==============================] - 16s 15ms/step - loss: 0.6772 - accuracy: 0.7075 - val_loss: 0.6926 - val_accuracy: 0.7076\n",
      "Epoch 29/50\n",
      "1090/1090 [==============================] - 16s 15ms/step - loss: 0.6793 - accuracy: 0.7062 - val_loss: 0.6642 - val_accuracy: 0.7154\n",
      "Epoch 30/50\n",
      "1090/1090 [==============================] - 15s 14ms/step - loss: 0.6758 - accuracy: 0.7076 - val_loss: 0.6902 - val_accuracy: 0.7036\n",
      "Epoch 31/50\n",
      "1090/1090 [==============================] - 17s 15ms/step - loss: 0.6769 - accuracy: 0.7077 - val_loss: 0.6650 - val_accuracy: 0.7148\n",
      "Epoch 32/50\n",
      "1090/1090 [==============================] - 16s 15ms/step - loss: 0.6761 - accuracy: 0.7084 - val_loss: 0.6909 - val_accuracy: 0.7127\n",
      "Epoch 33/50\n",
      "1090/1090 [==============================] - 15s 14ms/step - loss: 0.6710 - accuracy: 0.7103 - val_loss: 0.6739 - val_accuracy: 0.7174\n",
      "Epoch 34/50\n",
      "1090/1090 [==============================] - 14s 13ms/step - loss: 0.6726 - accuracy: 0.7093 - val_loss: 0.6713 - val_accuracy: 0.7100\n",
      "Epoch 35/50\n",
      "1090/1090 [==============================] - 15s 13ms/step - loss: 0.6726 - accuracy: 0.7093 - val_loss: 0.6606 - val_accuracy: 0.7162\n",
      "Epoch 36/50\n",
      "1090/1090 [==============================] - 15s 13ms/step - loss: 0.6700 - accuracy: 0.7106 - val_loss: 0.6653 - val_accuracy: 0.7184\n",
      "Epoch 37/50\n",
      "1090/1090 [==============================] - 15s 13ms/step - loss: 0.6699 - accuracy: 0.7103 - val_loss: 0.6850 - val_accuracy: 0.6992\n",
      "Epoch 38/50\n",
      "1090/1090 [==============================] - 13s 12ms/step - loss: 0.6703 - accuracy: 0.7112 - val_loss: 0.6698 - val_accuracy: 0.7136\n",
      "Epoch 39/50\n",
      "1090/1090 [==============================] - 14s 13ms/step - loss: 0.6688 - accuracy: 0.7117 - val_loss: 0.6664 - val_accuracy: 0.7113\n",
      "Epoch 40/50\n",
      "1090/1090 [==============================] - 15s 13ms/step - loss: 0.6685 - accuracy: 0.7112 - val_loss: 0.6755 - val_accuracy: 0.7058\n",
      "Epoch 41/50\n",
      "1090/1090 [==============================] - 13s 11ms/step - loss: 0.6671 - accuracy: 0.7114 - val_loss: 0.6759 - val_accuracy: 0.7106\n",
      "Epoch 42/50\n",
      "1090/1090 [==============================] - 12s 11ms/step - loss: 0.6662 - accuracy: 0.7121 - val_loss: 0.6805 - val_accuracy: 0.7047\n",
      "Epoch 43/50\n",
      "1090/1090 [==============================] - 15s 13ms/step - loss: 0.6656 - accuracy: 0.7120 - val_loss: 0.6647 - val_accuracy: 0.7161\n",
      "Epoch 44/50\n",
      "1090/1090 [==============================] - 15s 13ms/step - loss: 0.6646 - accuracy: 0.7123 - val_loss: 0.6605 - val_accuracy: 0.7184\n",
      "Epoch 45/50\n",
      "1090/1090 [==============================] - 15s 13ms/step - loss: 0.6653 - accuracy: 0.7126 - val_loss: 0.6580 - val_accuracy: 0.7173\n",
      "Epoch 46/50\n",
      "1090/1090 [==============================] - 14s 12ms/step - loss: 0.6632 - accuracy: 0.7138 - val_loss: 0.6603 - val_accuracy: 0.7180\n",
      "Epoch 47/50\n",
      "1090/1090 [==============================] - 15s 14ms/step - loss: 0.6624 - accuracy: 0.7137 - val_loss: 0.6567 - val_accuracy: 0.7194\n",
      "Epoch 48/50\n",
      "1090/1090 [==============================] - 14s 13ms/step - loss: 0.6608 - accuracy: 0.7148 - val_loss: 0.6610 - val_accuracy: 0.7159\n",
      "Epoch 49/50\n",
      "1090/1090 [==============================] - 15s 13ms/step - loss: 0.6604 - accuracy: 0.7145 - val_loss: 0.6633 - val_accuracy: 0.7153\n",
      "Epoch 50/50\n",
      "1090/1090 [==============================] - 14s 13ms/step - loss: 0.6600 - accuracy: 0.7151 - val_loss: 0.6609 - val_accuracy: 0.7168\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "model = RecurrentNetwork(X1, X2)\n",
    "history = model.fit([X1_train, X2_train], y_train, \n",
    "                    validation_split=0.1, \n",
    "                    batch_size=256, \n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jrd55gTA72vc",
    "outputId": "ec904073-21bf-4186-c7cf-8873d494e886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.714493080868359\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict([X1_test, X2_test])\n",
    "print(accuracy_score(preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGfG6GnD4aYp"
   },
   "source": [
    "# **4) Submission**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final training of the chosen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train a simple OnveVsRestClassifier using featurized data\n",
    "# model = RandomForestClassifier(n_estimators=300, criterion='entropy', max_features='auto')\n",
    "model = XGBClassifier(objective=\"multi:softprob\")\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "iHQx9-ebavCp"
   },
   "outputs": [],
   "source": [
    "# Predictions with the chosen model\n",
    "preds_submission = model.predict(df_submission)\n",
    "\n",
    "## Save results to submission file\n",
    "preds_submission_df = pd.DataFrame(preds_submission, columns=['change_type'])\n",
    "preds_submission_df.to_csv(\"sample_submission.csv\", index=True, index_label='Id')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
